{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4dbd45",
   "metadata": {},
   "source": [
    "## 사이킷런으로 구현해 보는 머신러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf8b239",
   "metadata": {},
   "source": [
    "### 회귀 모델 실습\n",
    "예제 데이터와 머신러닝의 회귀 모델을 이용해 데이터를 예측하는 모델을 만들어 보겠습니다. 예제 데이터는 $y_n$\n",
    " 이라는 라벨 값을 각각 가지는 입력 데이터 \n",
    "$x_n$\n",
    "  100개로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d840467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ed2ef9bcfa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "r = np.random.RandomState(10)\n",
    "x = 10 * r.rand(100)\n",
    "y = 2 * x - 3 * r.rand(100)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ccadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1513d179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe822626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f763265",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[7.71320643 0.20751949 6.33648235 7.48803883 4.98507012 2.24796646\n 1.98062865 7.60530712 1.69110837 0.88339814 6.85359818 9.53393346\n 0.03948266 5.12192263 8.12620962 6.12526067 7.21755317 2.91876068\n 9.17774123 7.14575783 5.42544368 1.42170048 3.7334076  6.74133615\n 4.41833174 4.34013993 6.17766978 5.13138243 6.50397182 6.01038953\n 8.05223197 5.21647152 9.08648881 3.19236089 0.90459349 3.00700057\n 1.13984362 8.28681326 0.46896319 6.26287148 5.47586156 8.19286996\n 1.9894754  8.56850302 3.51652639 7.54647692 2.95961707 8.8393648\n 3.25511638 1.65015898 3.92529244 0.93460375 8.21105658 1.5115202\n 3.84114449 9.44260712 9.87625475 4.56304547 8.26122844 2.51374134\n 5.97371648 9.0283176  5.34557949 5.90201363 0.39281767 3.57181759\n 0.7961309  3.05459918 3.30719312 7.73830296 0.39959209 4.29492178\n 3.14926872 6.36491143 3.4634715  0.43097356 8.79915175 7.63240587\n 8.78096643 4.17509144 6.05577564 5.13466627 5.97836648 2.62215661\n 3.00871309 0.25399782 3.03062561 2.42075875 5.57578189 5.6550702\n 4.75132247 2.92797976 0.64251061 9.78819146 3.39707844 4.95048631\n 9.77080726 4.40773825 3.18272805 5.19796986].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_41/352589828.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# ! 에러 발생\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    659\u001B[0m         \u001B[0maccept_sparse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpositive\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"csr\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"coo\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    660\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 661\u001B[0;31m         X, y = self._validate_data(\n\u001B[0m\u001B[1;32m    662\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_numeric\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    663\u001B[0m         )\n",
      "\u001B[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    570\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    954\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"y cannot be None\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    955\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 956\u001B[0;31m     X = check_array(\n\u001B[0m\u001B[1;32m    957\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    958\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[1;32m    759\u001B[0m             \u001B[0;31m# If input is 1D raise error\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    760\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 761\u001B[0;31m                 raise ValueError(\n\u001B[0m\u001B[1;32m    762\u001B[0m                     \u001B[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    763\u001B[0m                     \u001B[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[7.71320643 0.20751949 6.33648235 7.48803883 4.98507012 2.24796646\n 1.98062865 7.60530712 1.69110837 0.88339814 6.85359818 9.53393346\n 0.03948266 5.12192263 8.12620962 6.12526067 7.21755317 2.91876068\n 9.17774123 7.14575783 5.42544368 1.42170048 3.7334076  6.74133615\n 4.41833174 4.34013993 6.17766978 5.13138243 6.50397182 6.01038953\n 8.05223197 5.21647152 9.08648881 3.19236089 0.90459349 3.00700057\n 1.13984362 8.28681326 0.46896319 6.26287148 5.47586156 8.19286996\n 1.9894754  8.56850302 3.51652639 7.54647692 2.95961707 8.8393648\n 3.25511638 1.65015898 3.92529244 0.93460375 8.21105658 1.5115202\n 3.84114449 9.44260712 9.87625475 4.56304547 8.26122844 2.51374134\n 5.97371648 9.0283176  5.34557949 5.90201363 0.39281767 3.57181759\n 0.7961309  3.05459918 3.30719312 7.73830296 0.39959209 4.29492178\n 3.14926872 6.36491143 3.4634715  0.43097356 8.79915175 7.63240587\n 8.78096643 4.17509144 6.05577564 5.13466627 5.97836648 2.62215661\n 3.00871309 0.25399782 3.03062561 2.42075875 5.57578189 5.6550702\n 4.75132247 2.92797976 0.64251061 9.78819146 3.39707844 4.95048631\n 9.77080726 4.40773825 3.18272805 5.19796986].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# ! 에러 발생\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e04aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x.reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d3f591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee99895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.linspace(-1, 11, 100)\n",
    "X_new = x_new.reshape(100,1)\n",
    "y_new = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49676f00",
   "metadata": {},
   "source": [
    "### 잠깐 Tip!\n",
    "reshape() 함수에서 나머지 숫자를 -1로 넣으면 자동으로 남은 숫자를 계산해 줍니다. 즉, x_new의 인자의 개수가 100개이므로, (100, 1)의 형태나 (2, 50)의 형태 등으로 변환해 줄 수 있는데요. (2, -1)을 인자로 넣으면 (2, 50)의 형태로 자동으로 변환해 줍니다. 아래 코드를 통해 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f1b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = x_new.reshape(-1,1)\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d980e585",
   "metadata": {},
   "source": [
    "학습된 회귀 모델이 잘 예측했는지 모델의 성능을 평가해 보도록 하겠습니다. 앞에서 간단히 소개하였듯이 모델의 성능 평가 관련 모듈은 `sklearn.metrics`에 저장되어 있습니다. 회귀 모델의 경우 RMSE(Root Mean Square Error) 를 사용해 성능을 평가합니다.\n",
    "\n",
    "사이킷런의 RMSE 오차 관련 함수의 스펙을 직접 확인해 보고 코드로 구현해 보세요. (힌트! `mean_squared_error` 함수의 공식을 유심히 보세요. `np.sqrt`를 활용해 보세요.)\n",
    "\n",
    "- Scikit-learn: Mean Squared Error(https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279ff1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.299028215052264\n"
     ]
    }
   ],
   "source": [
    "# Q. 아래 mse를 구하는 과정을 직접 구현해보세요.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y, y_new))\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1279bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ed2dc6e1fa0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, label='input data')\n",
    "plt.plot(X_new, y_new, color='red', label='regression line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a494531",
   "metadata": {},
   "source": [
    "### datasets 모듈\n",
    "사이킷런은 데이터셋을 모듈로 제공하고 있으며 데이터에 대한 내용은 아래 공식 문서를 참고하세요.\n",
    "\n",
    "scikit-learn: Dataset loading utilities\n",
    "sklearn.datasets 모듈은 크게 dataset loaders와 dataset fetchers로 나뉘며, 각각 Toy dataset과 Real World dataset을 제공하고 있습니다. 우리는 Toy dataset을 다뤄볼 예정입니다.\n",
    "\n",
    "Toy dataset의 예시입니다.\n",
    "\n",
    "    datasets.load_boston(): 회귀 문제, 미국 보스턴 집값 예측(version 1.2 이후 삭제 예정)\n",
    "    datasets.load_breast_cancer(): 분류 문제, 유방암 판별\n",
    "    datasets.load_digits(): 분류 문제, 0 ~ 9 숫자 분류\n",
    "    datasets.load_iris(): 분류 문제, iris 품종 분류\n",
    "    datasets.load_wine(): 분류 문제, 와인 분류\n",
    "\n",
    "우리는 와인 데이터셋을 이용하겠습니다.\n",
    "\n",
    "#### datasets.load_wine() 뜯어보기\n",
    "와인 분류 데이터를 다운로드한 다음 data란 변수에 할당합니다. 그리고 자료형을 한번 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8154def1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec49ba9",
   "metadata": {},
   "source": [
    "sklearn.utils.Bunch라고 하는 데이터 타입이네요? 이 타입이 무엇인지 공식 문서를 통해 확인해 봅시다.\n",
    "\n",
    "- scikit-learn: sklearn.utils.Bunch(https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch)\n",
    "\n",
    "    Bunch는 파이썬의 딕셔너리와 유사한 형태의 데이터 타입입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e408a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
      "        1.065e+03],\n",
      "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
      "        1.050e+03],\n",
      "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
      "        1.185e+03],\n",
      "       ...,\n",
      "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
      "        8.350e+02],\n",
      "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
      "        8.400e+02],\n",
      "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
      "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2]), 'frame': None, 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14c092",
   "metadata": {},
   "source": [
    "data를 출력해 보면 데이터들이 중괄호에 {} 담겨있고 콜론 : 을 이용해서 구분되어 있습니다. 바로 key와 value입니다. 번치 데이터 타입에도 파이썬의 딕셔너리 메서드인 keys()를 사용할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf095d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917eadf6",
   "metadata": {},
   "source": [
    "어떤 값들이 나왔나요? 이 데이터의 각 키값이 의미하는 것이 무엇인지 하나씩 알아보도록 하겠습니다.\n",
    "\n",
    "### 1. data\n",
    "\n",
    "키값 data는 특성 행렬입니다. 파이썬의 딕셔너리와 유사하다고 했죠? 키에 접근하기 위해서 .을 사용할 수 있습니다. 한 번 확인해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a868da51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6869e",
   "metadata": {},
   "source": [
    "특성 행렬은 2차원이며 행에는 데이터의 개수(n_samples)가 열에는 특성의 개수(n_features)가 들어 있습니다. 모양을 확인해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "488342b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488eb72",
   "metadata": {},
   "source": [
    "(178, 13)이 나오네요. 즉, 특성이 13개, 데이터가 178개인 특성 행렬이 나왔습니다.\n",
    "\n",
    "ndim을 이용해 차원을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae7b7d5",
   "metadata": {},
   "source": [
    "### 2. target\n",
    "\n",
    "키값 target은 뭘까요? 예측하셨겠지만 타겟 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0818ed79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e0dfe",
   "metadata": {},
   "source": [
    "타겟 벡터는 1차원입니다. 그리고 타겟 벡터의 길이는 특성 행렬의 데이터 개수와 일치해야 합니다. 정말 그럴까요? 모양을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebf6564e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706981b8",
   "metadata": {},
   "source": [
    "`(178, )` 이 나오네요. 특성 행렬의 데이터 수와 일치합니다.\n",
    "\n",
    "### 3. feature_names\n",
    "\n",
    "`data` 키에 접근해서 `data`의 값을 확인해 본 결과 특성이 13개임을 확인했습니다. \n",
    "그럼 이 특성들의 이름이 뭔지 알아야겠죠? `feature_names`란 키에 특성들의 이름이 저장되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d55535b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c4b63",
   "metadata": {},
   "source": [
    "feature_names들이 저장되어 있네요, 전 와인에 대해 잘 몰라서... feature_names들이 무엇을 의미하는지 검색해 봐야 할 것 같아요. 그렇지만 feature의 개수 정도는 간단히 확인이 가능합니다. 내장함수 len()을 이용해서 확인해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b58a2",
   "metadata": {},
   "source": [
    "feature_names의 개수와 특성 행렬의 n_features(열)의 숫자가 일치하네요.\n",
    "\n",
    "### 4. target_names\n",
    "\n",
    "target_names는 분류하고자 하는 대상입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f898a1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c061c00f",
   "metadata": {},
   "source": [
    "출력값을 확인해 보니 다음과 같이 나옵니다.\n",
    "\n",
    "array(['class_0', 'class_1', 'class_2'], dtype='<U7')\n",
    "\n",
    "데이터를 각각 class_0과 class_1, class_2로 분류한다는 뜻입니다.\n",
    "\n",
    "와인의 종류가 상세하게 무엇을 의미하는지는 모르지만 각각 0번 와인, 1번 와인, 2번 와인으로 분류를 하는 문제네요.(와인 종류는 굳이 안 찾아보셔도 됩니다.)\n",
    "\n",
    "### 5. DESCR\n",
    "\n",
    "DESCR은 describe의 약자로 데이터에 대한 설명이에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aab261e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b20e6d",
   "metadata": {},
   "source": [
    "위 내용은 사이킷런 공식 문서에도 나와있습니다.\n",
    "\n",
    "sklearn.datasets.load_wine()(https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a138940",
   "metadata": {},
   "source": [
    "### 사이킷런 데이터셋을 이용한 분류 문제 실습\n",
    "#### DataFrame으로 나타내기\n",
    "특성 행렬을 Pandas의 DataFrame으로 나타낼 수 있다고 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36c89e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c924ed1",
   "metadata": {},
   "source": [
    "DataFrame으로 나타내니 한결 데이터 보기가 편해졌습니다. 이렇게 하면 EDA(Exploration Data Analysis)할 때 굉장히 편할 것 같네요.\n",
    "\n",
    "### 머신러닝\n",
    "이제 머신러닝 모델을 만들고 예측을 해보겠습니다.\n",
    "\n",
    "특성 행렬은 통상 변수명 X에 저장하고, 타겟 벡터는 y에 저장한다고 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "586ab667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18d4a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54aef9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b86c7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3ae51",
   "metadata": {},
   "source": [
    "그리고 성능을 평가해 보도록 하겠습니다. 성능은 sklearn.metrics 모듈을 사용한다고 했습니다. 분류 문제의 경우 classification_report 와 accuracy_score를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b0caf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        59\n",
      "           1       1.00      1.00      1.00        71\n",
      "           2       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00       178\n",
      "   macro avg       1.00      1.00      1.00       178\n",
      "weighted avg       1.00      1.00      1.00       178\n",
      "\n",
      "accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#타겟 벡터 즉 라벨인 변수명 y와 예측값 y_pred을 각각 인자로 넣습니다. \n",
    "print(classification_report(y, y_pred))\n",
    "#정확도를 출력합니다. \n",
    "print(\"accuracy = \", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5114ad",
   "metadata": {},
   "source": [
    "Q. 위 모델의 정확도가 어떻게 100%가 나왔을까요?\n",
    "\n",
    "데이터의 수가 너무 적어서 과대적합되었다\n",
    "train test set을 나누지 않아서 값들을 사실상 외워버린 것같다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca3680",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 테스트 데이터 직접 분리하기\n",
    "보통 훈련 데이터와 테스트 데이터의 비율은 8:2로 설정합니다. 자 그럼 데이터를 나누어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f963e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "print(data.data.shape)\n",
    "print(data.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a62ba94",
   "metadata": {},
   "source": [
    "전체 데이터의 개수는 178개입니다. 8 대 2로 특성 행렬과 타겟 벡터를 나누어 보도록 하겠습니다. 데이터의 개수이므로 정수만 가능하죠. 178개의 80%면 142.4이지만 정수로 표현해 142개, 그리고 훈련 데이터는 나머지 36개로 나누어 보겠습니다.\n",
    "\n",
    "특성 행렬과 타겟 벡터는 ndarray type이니 numpy의 슬라이싱을 사용하면 될 것 같네요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e18679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (36, 13)\n"
     ]
    }
   ],
   "source": [
    "X_train = data.data[:142]\n",
    "X_test = data.data[142:]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cfc14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142,) (36,)\n"
     ]
    }
   ],
   "source": [
    "y_train = data.target[:142]\n",
    "y_test = data.target[142:]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52ef8848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b25daaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6348fbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률= 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"정답률=\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7d86b",
   "metadata": {},
   "source": [
    "### train_test_split() 사용해서 분리하기\n",
    "훈련 데이터와 테스트 데이터 분리는 필수 기능입니다. 훈련에 쓴 데이터를 예측에 사용하면 항상 정확도는 100%가 나올 것이기 때문이죠. 사이킷런에서는 이 필수 기능을 당연히 API로 제공하고 있습니다. 바로 model_selection의 train_test_split() 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a80dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "result = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a823663",
   "metadata": {},
   "source": [
    "인자로 특성 행렬 X와 타겟 벡터 y를 넣고 테스트 데이터의 비율을 넣어 키워드 인자로 지정해 줍니다. 20%로 해 볼게요. 그리고 우리는 0번부터 순차적으로 데이터를 분할했죠? 사이킷런은 랜덤하게 데이터를 섞어주는 기능도 있습니다. random_state 인자에 seed 번호를 입력하면 됩니다. seed 번호는 임의로 결정할 수 있고, 같은 seed 번호를 사용하면 언제든 같은 결과를 얻을 수 있습니다.\n",
    "\n",
    "train_test_split()은 반환값으로 4개의 원소로 이루어진 list를 반환합니다. (*리스트 원소의 데이터 타입은 array입니다.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b87ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "240cfdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 13)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c5768a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97185a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2594118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73343cde",
   "metadata": {},
   "source": [
    "모양을 보니 감이 잡히시나요? 네 0번 원소부터 순서대로 훈련 데이터용 특성 행렬, 테스트 데이터용 특성 행렬, 훈련 데이터용 타겟 벡터, 테스트 데이터용 타겟 벡터입니다.\n",
    "\n",
    "우리는 이 함수를 이런 식으로 unpacking 해서 씁니다.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5c4cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250882a",
   "metadata": {},
   "source": [
    "### 실습\n",
    "그럼 앞서 와인 분류 문제의 데이터를 훈련용 데이터셋과 테스트용 데이터셋으로 나눈 뒤 훈련하고 예측하는 전체 코드를 직접 작성해 보세요.\n",
    "\n",
    ">와인 데이터가 간단하기 때문에 training/test 데이터가 어떻게 나누어지는가에 따라서 데이터를 분리했는데도 정확도 100%가 나올 수도 있습니다. random seed 번호를 지정하지 않은 경우 코드를 여러 번 실행시켜 보면 정확도가 다르게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e92209d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "# Q. 위에서 배운 내용을 토대로 내용을 정리해서 아래의 [[YOUR CODE]]를 완성해주세요.\n",
    "# 데이터셋 로드하기\n",
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# 훈련용 데이터셋 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# 훈련하기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측하기\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정답률 출력하기\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#타겟 벡터 즉 라벨인 변수명 y와 예측값 y_pred을 각각 인자로 넣습니다. \n",
    "print(classification_report(y_test, y_pred))\n",
    "#정확도를 출력합니다. \n",
    "print(\"accuracy = \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
