{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99678aa",
   "metadata": {},
   "source": [
    "# Regularizationê³¼ Normalization\n",
    "Regularizationê³¼ Normalization ì´ ë‘ ê°œë…ì€ ì„œë¡œ í—·ê°ˆë¦¬ëŠ” ê²½ìš°ê°€ ë§ì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë²ˆì—­í•  ë•Œ ë‘ ê°œë…ì´ ë‹¤ 'ì •ê·œí™”'ë¡œ ë²ˆì—­ë  ë•Œê°€ ë§ì•„ì„œ ë”ìš± í˜¼ë€ìŠ¤ëŸ¬ìš¸ ë•Œê°€ ë§ìŠµë‹ˆë‹¤. ìš°ì„  ë‘ ê°œë…ì„ ì•„ë˜ì™€ ê°™ì´ ì •ë¦¬í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Regularization(ì •ì¹™í™”)\n",
    "ì •ì¹™í™”ë¼ê³  ë¶ˆë¦¬ë©°, ì˜¤ë²„í”¼íŒ…(overfitting)ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²• ì¤‘ì˜ í•˜ë‚˜ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ìš°ë¦¬ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë‹¤ë£° ì£¼ì œì´ê¸°ë„ í•˜ì§€ìš”. L1, L2 Regularization, Dropout, Batch normalization ë“±ì´ ìˆìŠµë‹ˆë‹¤. ì˜¤ë²„í”¼íŒ…ì€ í•œêµ­ì–´ë¡œ ê³¼ì í•©ì´ë¼ê³  í•˜ë©°, train setì€ ë§¤ìš° ì˜ ë§íˆì§€ë§Œ, validation/test setì€ ë§íˆì§€ ëª»í•˜ëŠ” í˜„ìƒì„ ë§í•©ë‹ˆë‹¤. ë¹„ìœ í•˜ìë©´ ì˜¤ë²„í”¼íŒ…ì€ ê¸°ì¶œë¬¸ì œëŠ” ì™¸ì›Œì„œ ì˜ ë§íˆì§€ë§Œ ìƒˆë¡œìš´ ì‘ìš© ë¬¸ì œë¡œ ì‹œí—˜ì„ ë³¼ ë•ŒëŠ” ì˜ í’€ì§€ ëª»í•˜ëŠ” ê²½ìš°ë¼ê³  í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” ìƒˆë¡œìš´ ì‹œí—˜, ì¦‰ test setì—ì„œë„ ì˜ ë§í˜€ì•¼ê² ì£ ? ê·¸ë˜ì„œ regularization ê¸°ë²•ë“¤ì€ ëª¨ë¸ì— ì œì•½ ì¡°ê±´ì„ ê±¸ì–´ì„œ ëª¨ë¸ì˜ train lossë¥¼ ì¦ê°€ì‹œí‚¤ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ train lossëŠ” ì•½ê°„ ì¦ê°€í•˜ì§€ë§Œ ê²°ê³¼ì ìœ¼ë¡œ, validation lossë‚˜ ìµœì¢… test lossë¥¼ ê°ì†Œì‹œí‚¤ë ¤ëŠ” ëª©ì ì„ ê°€ì§€ê³  ìˆì§€ìš”.\n",
    "\n",
    "## Normalization(ì •ê·œí™”)\n",
    "ì •ê·œí™”ë¼ê³  ë¶ˆë¦¬ë©°, ì´ëŠ” ë°ì´í„°ì˜ í˜•íƒœë¥¼ ì¢€ ë” ì˜ë¯¸ ìˆê²Œ, í˜¹ì€ íŠ¸ë ˆì´ë‹ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ z-scoreë¡œ ë°”ê¾¸ê±°ë‚˜ minmax scalerë¥¼ ì‚¬ìš©í•˜ì—¬ 0ê³¼ 1ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë¶„í¬ë¥¼ ì¡°ì •í•˜ëŠ” ê²ƒë“¤ì´ í•´ë‹¹ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸ˆì•¡ê³¼ ê°™ì€ í° ë²”ìœ„ì˜ ê°’(10,000 ~ 10,000,000)ê³¼ ì‹œê°„(0~24)ì˜ ê°’ì´ ë“¤ì–´ê°€ëŠ” ê²½ìš°, ë°ì´í„°ì˜ ë¶„í¬ê°€ í”¼ì²˜(feature) ê°’ì˜ ë²”ìœ„ì— ì˜í•´ ì™œê³¡ë˜ì–´ í•™ìŠµì— ë°©í•´ê°€ ëœë‹¤ëŠ” ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. normalizationì€ ëª¨ë“  í”¼ì²˜ ê°’ì˜ ë²”ìœ„ë¥¼ ë™ì¼í•˜ê²Œ í•˜ì—¬ ëª¨ë¸ì´ í’€ì–´ì•¼ í•˜ëŠ” ë¬¸ì œë¥¼ ì¢€ ë” ê°„ë‹¨í•˜ê²Œ ë°”ê¾¸ì–´ ì£¼ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë‘ ê°€ì§€ ë‹¨ì–´ëŠ” í•œêµ­ì–´ë¡œ ë²ˆì—­ ì‹œì— í˜¼ìš©í•˜ì—¬ ì“°ê¸°ë„ í•˜ë¯€ë¡œ, ì•ìœ¼ë¡œ ì´ë²ˆ ë…¸ë“œì—ì„œëŠ” ì£¼ë¡œ ì˜ì–´ë¡œ í‘œê¸°í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. í•µì‹¬ì„ ì •ë¦¬í•˜ë©´, regularizationì€ ì˜¤ë²„í”¼íŒ…ì„ ë§‰ê³ ì í•˜ëŠ” ë°©ë²•, normalizationì€ íŠ¸ë ˆì´ë‹ì„ í•  ë•Œì— ì„œë¡œ ë²”ìœ„ê°€ ë‹¤ë¥¸ ë°ì´í„°ë“¤ì„ ê°™ì€ ë²”ìœ„ë¡œ ë°”ê¿”ì£¼ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì´ë¼ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "Regularizationì™€ Normalizationì˜ ê°„ë‹¨í•œ ì˜ˆì œë¥¼ Iris datasetì˜ íšŒê·€ ë¬¸ì œë¥¼ í’€ë©´ì„œ ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "3b49e91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:23.530876Z",
     "start_time": "2024-05-24T08:40:23.396848Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "target_df = pd.DataFrame(data=iris.target, columns=['species'])\n",
    "\n",
    "# 0, 1, 2ë¡œ ë˜ì–´ìˆëŠ” target ë°ì´í„°ë¥¼ \n",
    "# ì•Œì•„ë³´ê¸° ì‰½ê²Œ 'setosa', 'versicolor', 'virginica'ë¡œ ë°”ê¿‰ë‹ˆë‹¤ \n",
    "def converter(species):\n",
    "    if species == 0:\n",
    "        return 'setosa'\n",
    "    elif species == 1:\n",
    "        return 'versicolor'\n",
    "    else:\n",
    "        return 'virginica'\n",
    "\n",
    "target_df['species'] = target_df['species'].apply(converter)\n",
    "\n",
    "iris_df = pd.concat([iris_df, target_df], axis=1)\n",
    "iris_df.head()"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "22baa482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:23.537074Z",
     "start_time": "2024-05-24T08:40:23.532101Z"
    }
   },
   "source": [
    "X = [iris_df['petal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n",
    "Y = [iris_df['sepal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n",
    "\n",
    "print(\"petal length(ê½ƒì ê¸¸ì´)\", X)\n",
    "print(\"sepal length(ê½ƒë°›ì¹¨ì˜ ê¸¸ì´)\", Y)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "699a70e1",
   "metadata": {},
   "source": [
    "ê°’ìœ¼ë¡œë§Œ ë³´ë‹ˆ ì§ê´€ì ìœ¼ë¡œ ì˜ ì™€ë‹¿ì§€ ì•Šë„¤ìš”! ì‚°ì ë„ë¡œ ê·¸ë ¤ë´…ì‹œë‹¤.\n",
    "\n",
    "ì•„ì§ normalizationì„ í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— xì¶•ê³¼ yì¶•ì€ ê°ê°ì˜ ìµœì†Ÿê°’ê³¼ ìµœëŒ“ê°’ì˜ ë²”ìœ„ë¡œ ê·¸ë ¤ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "0f0bca5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:23.730274Z",
     "start_time": "2024-05-24T08:40:23.539647Z"
    }
   },
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X,Y)\n",
    "plt.title('petal-sepal scatter before normalization') \n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d7f61c6b",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ì˜ ì¶•ì„ ì˜ ì‚´í´ë³´ì„¸ìš”!\n",
    "\n",
    "ì´ì œ 0-1ë¡œ normalizationì„ í•´ì£¼ëŠ” minmax_scaleë¥¼ ì´ìš©í•´ì„œ ì‚°ì ë„ë¥¼ ë‹¤ì‹œ í•œë²ˆ ê·¸ë ¤ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "78419868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:23.847351Z",
     "start_time": "2024-05-24T08:40:23.731865Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "X_scale = minmax_scale(X)\n",
    "Y_scale = minmax_scale(Y)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X_scale,Y_scale)\n",
    "plt.title('petal-sepal scatter after normalization') \n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2f653f05",
   "metadata": {},
   "source": [
    "ê²°ê³¼ë¥¼ ë¹„êµí•´ ë³´ë©´, ê°€ì¥ í° ê°’ì„ 1, ê°€ì¥ ì‘ì€ ê°’ì„ 0ìœ¼ë¡œ í•˜ì—¬ ì¶• ë²”ìœ„ê°€ ë°”ë€œì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ ìƒëŒ€ì ì¸ ë¶„í¬ëŠ” ë°”ë€Œì§€ ì•Šì•˜ì§€ë§Œ, í”¼ì²˜ì˜ ìŠ¤ì¼€ì¼ì´ 0ê³¼ 1 ì‚¬ì´ë¡œ ë³€í™˜ë˜ì—ˆìœ¼ë¯€ë¡œ ì´í›„ X, Yì˜ ê´€ê³„ë¥¼ ë‹¤ë£¨ê¸° ìš©ì´í•´ì¡ŒìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì—” ê°™ì€ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ íšŒê·€ ë¬¸ì œë¥¼ í’€ë©´ì„œ regularizationì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "sklearn.linear_modelì— í¬í•¨ëœ LinearRegression ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ X-Y ê´€ê³„ë¥¼ ì„ í˜•ìœ¼ë¡œ ëª¨ë¸ë§í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ sklearn.linear_modelì—ëŠ” L1, L2 regressionì¸ Lassoì™€ Ridge ëª¨ë¸ë„ í•¨ê»˜ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì´ë“¤ì˜ ì°¨ì´ì ì„ ë¨¼ì € ì§ê´€ì ìœ¼ë¡œ ì´í•´í•´ ë³´ê² ìŠµë‹ˆë‹¤. ìˆ˜í•™ì  ì •ì˜ë‚˜ ë³´ë‹¤ êµ¬ì²´ì ì¸ ì„¤ëª…ì€ ë‹¤ìŒ ìŠ¤í…ì— ì´ì–´ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "e939f168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:23.961833Z",
     "start_time": "2024-05-24T08:40:23.848125Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np \n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Iris Datasetì„ Linear Regressionìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. \n",
    "linear= LinearRegression()\n",
    "linear.fit(X.reshape(-1,1), Y)\n",
    "\n",
    "# Linear Regressionì˜ ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì„ í™•ì¸í•©ë‹ˆë‹¤. \n",
    "a, b=linear.coef_, linear.intercept_\n",
    "print(\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\" %(a,b))"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fe17f1",
   "metadata": {},
   "source": [
    "ìœ„ì—ì„œ linear regressionìœ¼ë¡œ êµ¬í•œ ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì„ ê°€ì§€ê³  ì¼ì°¨í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ì‚°ì ë„ì™€ í•¨ê»˜ ê·¸ë ¤ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "61740390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.074223Z",
     "start_time": "2024-05-24T08:40:23.962895Z"
    }
   },
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(X,linear.predict(X.reshape(-1,1)),'-b')\n",
    "plt.title('petal-sepal scatter with linear regression') \n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "685468a9",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” L1, L2 regularizationìœ¼ë¡œ regressionì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ëŠ” Lasso, Ridgeë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
    "\n",
    "ë¨¼ì € L1 regularizationì¸ Lassoë¡œ ë¬¸ì œë¥¼ í’€ì–´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c143d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.184225Z",
     "start_time": "2024-05-24T08:40:24.075064Z"
    }
   },
   "source": [
    "# Q. linear regressionì˜ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬, ì•„ë˜ ì½”ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”!\n",
    "\n",
    "# L1 regularizationì€ Lassoë¡œ import í•©ë‹ˆë‹¤.\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "L1 = Lasso()\n",
    "L1.fit(X.reshape(-1,1), Y)\n",
    "a, b = L1.coef_, L1.intercept_\n",
    "print(\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\" %(a,b))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(X, L1.predict(X.reshape(-1, 1)), '-b')\n",
    "plt.title('petal-sepal scatter with L1 regularization(Lasso)') \n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b38723d6",
   "metadata": {},
   "source": [
    "ì–´ë–¤ê°€ìš”? í˜¹ì‹œ ê¸°ìš¸ê¸°ê°€ 0ìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šì•˜ë‚˜ìš”? Lasso ë°©ë²•ì€ ê²°ê³¼ê°€ ë³„ë¡œ ì¢‹ì§€ ì•Šì€ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ê°™ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ L2 regularizationì¸ Ridgeë¡œ ë¬¸ì œë¥¼ í’€ì–´ë³´ê³  ì„œë¡œ ë¹„êµí•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "5bc8b6f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.299420Z",
     "start_time": "2024-05-24T08:40:24.185521Z"
    }
   },
   "source": [
    "# Q. linear regressionì˜ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬, ì•„ë˜ ì½”ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”!\n",
    "\n",
    "# L2 regularizationì€ Ridgeë¡œ import í•©ë‹ˆë‹¤.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "L2 = Ridge()\n",
    "L2.fit(X.reshape(-1, 1), Y)\n",
    "a, b = L1.coef_, L2.intercept_\n",
    "print(\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\" %(a,b))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(X, L2.predict(X.reshape(-1, 1)), '-b')\n",
    "plt.title('petal-sepal scatter with L2 regularization(Ridge)') \n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7abdf894",
   "metadata": {},
   "source": [
    "ë‹¤ì‹œ ë‹¤ë£¨ê² ì§€ë§Œ, linear regressionì´ L2 normê³¼ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ L2 regularizationì„ ì“°ëŠ” Ridgeë°©ë²•ìœ¼ë¡œëŠ” ì•ì„œ linear regressionê³¼ í° ì°¨ì´ê°€ ì—†ëŠ” ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "ê·¸ëŸ¬ë‚˜ ì™œ L1 regularizationì„ ì“°ëŠ” Lassoì—ì„œëŠ” ì´ìƒí•œ ê²°ê³¼ê°€ ë‚˜ì™”ì„ê¹Œìš”?\n",
    "\n",
    "ë‹¤ìŒ ìŠ¤í…ì—ì„œ ê·¸ ì´ìœ ë¥¼ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb6f77",
   "metadata": {},
   "source": [
    "## L1 Regularization\n",
    "ì´ì „ ìŠ¤í…ì—ì„œ regularizationê³¼ normalizationì˜ ì •ì˜ë¥¼ ì„¤ëª…í•˜ê³ , L1/L2 regularizationì„ ì½”ë“œë¡œ ë§›ë³´ê¸° í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ì— ê°™ì€ linear regression ë¬¸ì œë¥¼ í‘¸ëŠ”ë° L1 regularizationì—ì„œëŠ” ë¬¸ì œê°€ í’€ë¦¬ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì„ ê¸°ì–µí•˜ì‹œë‚˜ìš”?\n",
    "\n",
    "L1 regularizationì„ ì„¤ëª…í•˜ë©´ì„œ, ì§€ë‚œ ìŠ¤í…ì—ì„œ `Lasso`ë¡œëŠ” regression ë¬¸ì œê°€ ì œëŒ€ë¡œ í’€ë¦¬ì§€ ì•Šì•˜ë˜ í˜„ìƒì„ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì–´ë–¤ ë•Œì— L1 regularizationì„ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œì•„ë³´ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤!\n",
    "\n",
    "### L1 regularization (Lasso)ì˜ ì •ì˜\n",
    "L1 regularizationì€ ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤. ($N$: ë°ì´í„°ì˜ ê°œìˆ˜, $D$: ë°ì´í„°ì˜ ì°¨ì›(featureì˜ ê°œìˆ˜))\n",
    "\n",
    "$$  \\hat{\\beta}^{lasso} := argmin_{\\beta} \\frac{1}{2N} \\sum_{i=1}^{N}(y_i - \\beta_0 - \\sum_{j=1}^{D}x_{ij}\\beta_j)^2 + \\lambda\\sum_{j=1}^{D} \\left| \\beta_j \\right| $$\n",
    "\n",
    "ì—¬ê¸°ì„œ ì¤‘ìš”í•˜ê²Œ ë´ì•¼ í•  ë¶€ë¶„ì€ $\\lambda\\sum_{j=1}^{D} \\left| \\beta_j \\right|$ì…ë‹ˆë‹¤. ì´ ë¶€ë¶„ì´ ì—†ë‹¤ë©´ linear regressionê³¼ ë™ì¼í•©ë‹ˆë‹¤\n",
    "\n",
    "ì´ ë¶€ë¶„ì´ ë°”ë¡œ L1 normì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì¸ë°, L1 regularizationì´ë¼ëŠ” ì´ë¦„ì´ ë¶™ì€ ì´ìœ ì´ê¸°ë„ í•˜ê³ , L2 regularizationê³¼ì˜ ì°¨ì´ê°€ ë‚˜íƒ€ë‚˜ëŠ” ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
    "\n",
    ">ğŸ’¡ì°¸ê³  ì§€ì‹ (Lp norm)\n",
    "\n",
    ">normì€ ë²¡í„°ë‚˜ í–‰ë ¬, í•¨ìˆ˜ ë“±ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê²ƒìœ¼ë¡œ ìš°ë¦¬ëŠ” ì—¬ê¸°ì„œ ë²¡í„°ê°’ë§Œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤. Lp norm ì˜ ì •ì˜ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.      \n",
    ">    (ì°¸ê³ ) Norm (mathematics)(https://en.wikipedia.org/wiki/Norm_(mathematics))\n",
    "\n",
    "$$ \\left\\| x\\right\\|_p := (\\sum_{i=1}^{n}\\left| x_i\\right|^p)^{1/p} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba8569",
   "metadata": {},
   "source": [
    "normì— ëŒ€í•´ì„œëŠ” ì´í›„ ìŠ¤í…ì—ì„œ ë” ìì„¸íˆ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤!\n",
    "\n",
    "ê·¸ë ‡ë‹¤ë©´\n",
    "$p=1$ì¸ ê²½ìš°ì˜ L1 normì€ \n",
    "$ \\left\\| x\\right\\|_1 := \\sum_{i=1}^{n}\\left| x_i\\right| $ ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ëŠ” ìœ„ì—ì„œ ë´¤ë˜ $\\lambda\\sum_{j=1}^{D} \\left| \\beta_j \\right|$ ì— ë“¤ì–´ê°€ ìˆëŠ” ìˆ˜ì‹ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤!    \n",
    "\n",
    "\n",
    "ë•Œë¬¸ì— $p=1$ì´ë¯€ë¡œ L1 regularizationì´ë¼ê³  ë¶€ë¥´ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "í•˜ì§€ë§Œ ì‚¬ì´í‚·ëŸ°ì´ë‚˜ ì¼€ë¼ìŠ¤, í…ì„œí”Œë¡œìš° ë“±ì˜ íŒ¨í‚¤ì§€ì—ì„œëŠ” `Lasso` ë¼ëŠ” ì´ë¦„ì„ ë” ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¼ ì €ë²ˆ ì‹œê°„ì— ì‚¬ìš©í•´ ë³¸ ì½”ë“œì˜ ì¼ë¶€ë¶„ì„ ì‚´í´ë³¼ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcf37063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.311353Z",
     "start_time": "2024-05-24T08:40:24.302753Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "target_df = pd.DataFrame(data=iris.target, columns=['species'])\n",
    "\n",
    "def converter(species):\n",
    "    if species == 0:\n",
    "        return 'setosa'\n",
    "    elif species == 1:\n",
    "        return 'versicolor'\n",
    "    else:\n",
    "        return 'virginica'\n",
    "\n",
    "target_df['species'] = target_df['species'].apply(converter)\n",
    "\n",
    "iris_df = pd.concat([iris_df, target_df], axis=1)\n",
    "iris_df.head()"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4e3a7676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.419812Z",
     "start_time": "2024-05-24T08:40:24.312067Z"
    }
   },
   "source": [
    "X = [iris_df['petal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n",
    "Y = [iris_df['sepal length (cm)'][a] for a in iris_df.index if iris_df['species'][a]=='virginica']\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X,Y)\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3b296087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.523067Z",
     "start_time": "2024-05-24T08:40:24.420599Z"
    }
   },
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "L1 = Lasso()\n",
    "L1.fit(X.reshape(-1,1), Y)\n",
    "a, b = L1.coef_, L1.intercept_\n",
    "print(\"ê¸°ìš¸ê¸° : %0.2f, ì ˆí¸ : %0.2f\" %(a,b))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X,Y)\n",
    "plt.plot(X,L1.predict(X.reshape(-1,1)),'-b')\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('sepal length (cm)')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd70dc4",
   "metadata": {},
   "source": [
    "í ... ê¸°ìš¸ê¸°ê°€ 0ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²ƒì´ ì•„ë¬´ë˜ë„ ì´ìƒí•œë°ìš”...ğŸ¤”\n",
    "ì•„ë¬´ë˜ë„ ë°ì´í„°ì˜ feature ê°œìˆ˜ê°€ 2ê°œë°–ì— ë˜ì§€ ì•Šìœ¼ë‹ˆê¹Œ ì´ê²Œ ë§ëŠ” ê±´ì§€ ì•„ì§ ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ì¼ë‹¨ ë‹¤ë¥¸ ë°ì´í„°ì…‹ìœ¼ë¡œ L1 regularizationì„ í•œë²ˆ ë” ëŒë ¤ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e69a6",
   "metadata": {},
   "source": [
    "### ì»¬ëŸ¼ ìˆ˜ê°€ ë§ì€ ë°ì´í„°ì—ì„œì˜ L1 regularization ë¹„êµ\n",
    "Iris ë°ì´í„°ëŠ” íŠ¹ì„±ì´ ì´ 4ê°œë¡œ ì»¬ëŸ¼ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë‹ˆ wine datasetì„ ì´ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "ì´ 13ê°œì˜ íŠ¹ì„±ì„ ê°–ëŠ” ë°ì´í„°ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "4f5d195b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.535162Z",
     "start_time": "2024-05-24T08:40:24.524305Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "target_df = pd.DataFrame(data=wine.target, columns=['Y'])"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e5a7beab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.542616Z",
     "start_time": "2024-05-24T08:40:24.535954Z"
    }
   },
   "source": [
    "wine_df.head(5)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4e54026d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.547669Z",
     "start_time": "2024-05-24T08:40:24.543330Z"
    }
   },
   "source": [
    "target_df.head(5)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab22d45",
   "metadata": {},
   "source": [
    "ë¨¼ì € linear regression ìœ¼ë¡œ ë¬¸ì œë¥¼ í’€ê³ , ê·¸ ê³„ìˆ˜(coefficient)ì™€ ì ˆëŒ€ ì˜¤ì°¨(mean absolute error), ì œê³± ì˜¤ì°¨(mean squared error), í‰ê·  ì œê³±ê°’ ì˜¤ì°¨(root mean squared error)ë¥¼ ì¶œë ¥í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "5c9e632e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.558298Z",
     "start_time": "2024-05-24T08:40:24.548812Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê³ \n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_df, target_df, test_size=0.3, random_state=101)\n",
    "\n",
    "# ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³¼ê¹Œìš”?\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ì´ë ‡ìŠµë‹ˆë‹¤!\n",
    "print(\"result of linear regression\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "print(\"\\n\\n coefficient linear regression\")\n",
    "print(model.coef_)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "58be7bb3",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” L1 regularizationìœ¼ë¡œ ë¬¸ì œë¥¼ í’€ì–´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "9233aae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.568026Z",
     "start_time": "2024-05-24T08:40:24.559603Z"
    }
   },
   "source": [
    "# Q. ìœ„ì˜ Iris ì˜ˆì œ ì½”ë“œë¥¼ ì°¸ê³ í•´ì„œ, ë¹ˆì¹¸ì„ ì±„ì›Œë´…ì‹œë‹¤.\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ëª¨ë¸ì„ ì¤€ë¹„í•˜ê³  í›ˆë ¨ì‹œí‚µë‹ˆë‹¤.\n",
    "L1 = Lasso(alpha=0.05)\n",
    "L1.fit(X_train, y_train)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ë¥¼ í•´ë´…ì‹œë‹¤.\n",
    "pred = L1.predict(X_test)\n",
    "\n",
    "# ëª¨ë¸ ì„±ëŠ¥ì€ ì–¼ë§ˆë‚˜ ì¢‹ì„ê¹Œìš”?\n",
    "print(\"Result of Lasso\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "print(\"\\n\\n coefficient of Lasso\")\n",
    "print(L1.coef_)"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3e8fa4e5",
   "metadata": {},
   "source": [
    "### ê²°ê³¼ ë¶„ì„\n",
    "coefficient ë¶€ë¶„ì„ ë³´ì‹œë©´ linear regressionê³¼ L1 regularizationì˜ ì°¨ì´ê°€ ì¢€ ë” ë‘ë“œëŸ¬ì§ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. linear regressionì—ì„œëŠ” ëª¨ë“  ì»¬ëŸ¼ì˜ ê°€ì¤‘ì¹˜ê°€ 0ì´ ì•„ë‹Œ ê°’ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, L1 regularizationì—ì„œëŠ” ì´ 13ê°œ ì¤‘ 7ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ì˜ ê°’ë“¤ì´ ëª¨ë‘ 0ì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. error ë¶€ë¶„ì—ì„œëŠ” í° ì°¨ì´ê°€ ì—†ì—ˆì§€ë§Œ, ìš°ë¦¬ê°€ ì–´ë–¤ ì»¬ëŸ¼ì´ ê²°ê³¼ì— ì˜í–¥ì„ ë” í¬ê²Œ ë¯¸ì¹˜ëŠ”ì§€ í™•ì‹¤íˆ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° ë‹¤ë¥¸ ë¬¸ì œì—ì„œë„ errorì˜ ì°¨ì´ê°€ í¬ê²Œ ë‚˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì°¨ì› ì¶•ì†Œì™€ ë¹„ìŠ·í•œ ê°œë…ìœ¼ë¡œ ë³€ìˆ˜ì˜ ê°’ì„ 7ê°œë§Œ ë‚¨ê²¨ë„ ì¶©ë¶„íˆ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ linear regressionê³¼ L1, L2 regularizationì˜ ì°¨ì´ ì¤‘ í•˜ë‚˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°(ìˆ˜ì‹ì—ì„œëŠ” ğœ†)ê°€ í•˜ë‚˜ ë” ë“¤ì–´ê°„ë‹¤ëŠ” ê²ƒì´ê³ , ê·¸ ê°’ì— ë”°ë¼ errorì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec3adc",
   "metadata": {},
   "source": [
    "## L2 Regularization\n",
    "### L2 Regularization(Ridge)ì˜ ì •ì˜\n",
    "L2 regularizationì€ ì•„ë˜ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ì •ì˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "$$\\hat{\\beta}^{ridge} := argmin_{\\beta} \\frac{1}{2N} \\sum_{i=1}^{N}(y_i - \\beta_0 - \\sum_{j=1}^{D}x_{ij}\\beta_j)^2 + \\lambda\\sum_{j=1}^{D} \\beta_j^2$$\n",
    "\n",
    "ì•„ë˜ëŠ” L1 regularizationì˜ ì •ì˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "$$  \\hat{\\beta}^{lasso} := argmin_{\\beta} \\frac{1}{2N} \\sum_{i=1}^{N}(y_i - \\beta_0 - \\sum_{j=1}^{D}x_{ij}\\beta_j)^2 + \\lambda\\sum_{j=1}^{D} \\left| \\beta_j \\right| $$\n",
    "\n",
    "ì ì´ì œ ë‘ regularization ìˆ˜ì‹ì˜ ì°¨ì´ê°€ ì–´ë””ì— ìˆëŠ”ì§€ ë³´ì´ì‹œë‚˜ìš”? ì´ì „ ìŠ¤í…ì—ì„œ ì ê¹ Lp normì„ ì„¤ëª…ë“œë ¸ëŠ”ë°, ê·¸ê²ƒì´ L1 / L2 regularizationì˜ ì´ë¦„ê³¼ í° ê´€ë ¨ì´ ìˆë‹¤ê³  í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "L2 regularizationì—ì„œëŠ” $\\lambda\\sum_{j=1}^{D} \\beta_j^2$ ë¶€ë¶„ì´ í•µì‹¬ ë‚´ìš©ì´ ë©ë‹ˆë‹¤.    \n",
    "$\\sum_{j=1}^{D} \\beta_j^2 \\leftarrow $ ì´ë¶€ë¶„ì´ ì´ì „ ìŠ¤í…ì—ì„œ ì„¤ëª…í•´ë“œë¦° L2 Normì˜ í˜•íƒœì™€ ë˜‘ê°™ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761aa808",
   "metadata": {},
   "source": [
    "### L1 / L2 Regularizationì˜ ì°¨ì´ì \n",
    "- ë…¸ì…˜ì— ì •ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc80e42",
   "metadata": {},
   "source": "![IMG](data/img.png)"
  },
  {
   "cell_type": "code",
   "id": "299af8fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.573174Z",
     "start_time": "2024-05-24T08:40:24.568729Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "wine = load_wine()\n",
    "wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "target_df = pd.DataFrame(data=wine.target, columns=['Y'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_df, target_df, test_size= 0.3, random_state=101)\n",
    "print('=3')"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cffa398e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.580819Z",
     "start_time": "2024-05-24T08:40:24.573801Z"
    }
   },
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "L1 = Lasso(alpha=0.05, max_iter=5)\n",
    "L1.fit(X_train, y_train)\n",
    "pred = L1.predict(X_test)\n",
    "\n",
    "print(\"result of Lasso\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "print(\"\\n\\n coefficient of Lasso\")\n",
    "print(L1.coef_)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3cc38adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.587767Z",
     "start_time": "2024-05-24T08:40:24.581712Z"
    }
   },
   "source": [
    "# Q. L1 regularization ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ì•„ë˜ ì½”ë“œë¥¼ ì±„ì›Œì£¼ì„¸ìš”.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "L2 = Ridge(alpha=0.05, max_iter=5)\n",
    "L2.fit(X_train, y_train)\n",
    "pred = L2.predict(X_test)\n",
    "\n",
    "print(\"result of Ridge\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, pred))\n",
    "print('Mean Root Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))\n",
    "\n",
    "print(\"\\n\\n coefficient of Ridge\")\n",
    "print(L2.coef_)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1c25a036",
   "metadata": {},
   "source": [
    "iteration ê°’ì„ 5ë¡œë§Œ ì„¤ì •í•´ ë³´ì•„ë„, L2 regularizationì˜ ê²°ê³¼ëŠ” linear regressionê³¼ ê°™ì€ ê°’ì´ ë‚˜ì˜¤ì§€ë§Œ, L1 regularizationì—ì„œëŠ” ì• stepê³¼ ê°™ì€ ê°’ì„ í™•ì¸í•  ìˆ˜ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤. ì‹¬ì§€ì–´ ìˆ˜ë ´í•˜ì§€ ì•Šì•˜ë‹¤ëŠ” ê²½ê³ ê¹Œì§€ ë‚˜ì˜¤ëŠ”êµ°ìš”! ì´ëŠ” ì•„ì§ ë‹¤ë¥¸ ì¡°ê±´ë“¤ì„ ë§Œì¡±í•˜ëŠ” ë‹µì„ ì°¾ì§€ ëª»í•˜ì˜€ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì •ë¦¬í•˜ë©´, L1 regularizationì€ ê°€ì¤‘ì¹˜ê°€ ì ì€ ë²¡í„°ì— í•´ë‹¹í•˜ëŠ” ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë³´ë‚´ë©´ì„œ ì°¨ì› ì¶•ì†Œì™€ ë¹„ìŠ·í•œ ì—­í• ì„ í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë©°, L2 regularizationì€ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë³´ë‚´ì§€ëŠ” ì•Šì§€ë§Œ ì œê³± í…€ì´ ìˆê¸° ë•Œë¬¸ì— L1 regularizationë³´ë‹¤ëŠ” ìˆ˜ë ´ ì†ë„ê°€ ë¹ ë¥´ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \n",
    "A=[1,1,1,1,1] , \n",
    "B=[5,0,0,0,0] ì˜ ê²½ìš° L1-normì€ ê°™ì§€ë§Œ, L2-normì€ ê°™ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¦‰, ì œê³± í…€ì—ì„œ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê°’ì€ ë” í¬ê²Œ, ê²°ê³¼ì— ì˜í–¥ì´ ì ì€ ê°’ë“¤ì€ ë” ì‘ê²Œ ë³´ë‚´ë©´ì„œ ìˆ˜ë ´ ì†ë„ê°€ ë¹¨ë¼ì§€ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬ë¯€ë¡œ, ë°ì´í„°ì— ë”°ë¼ ì ì ˆí•œ regularization ë°©ë²•ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fe1e4",
   "metadata": {},
   "source": [
    "## Extra : Lp norm\n",
    "ì´ì „ ìŠ¤í…ì—ì„œ ì ê¹ ì†Œê°œí•´ë“œë¦° Lp normì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "Normì´ë¼ëŠ” ìš©ì–´ëŠ” ë²¡í„°ë¿ë§Œ ì•„ë‹ˆë¼ í•¨ìˆ˜, í–‰ë ¬ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°œë…ìœ¼ë¡œ, ë”¥ëŸ¬ë‹ì„ ë°°ìš°ëŠ” ê³¼ì •ì—ì„œëŠ” ì£¼ë¡œ ë²¡í„°, ì¢€ ë” ì–´ë µê²ŒëŠ” í–‰ë ¬ì˜ norm ì •ë„ë§Œ ì•Œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "### Vector norm\n",
    "L1 / L2 regularizationì—ì„œ ë°°ìš´ normì€ ë²¡í„°ì—ì„œ ì •ì˜ëœ normìœ¼ë¡œ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "$$ \\left\\| x\\right\\|_p := (\\sum_{i=1}^{n}\\left| x_i\\right|^p)^{1/p} $$\n",
    "\n",
    "ì•„ë˜ ì½”ë“œì—ì„œ \n",
    "pì˜ ê°’ê³¼ \n",
    "xì˜ í˜•íƒœë¥¼ ë°”ê¾¸ì–´ê°€ë©° ì‹¤í—˜í•´ ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3bb8cec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.590136Z",
     "start_time": "2024-05-24T08:40:24.588493Z"
    }
   },
   "source": [
    "import numpy as np"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3bf4c0a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.597365Z",
     "start_time": "2024-05-24T08:40:24.591203Z"
    }
   },
   "source": [
    "# [Playground] xì™€ pë¥¼ ë°”ê¾¸ì–´ê°€ë©° norm ê°’ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì‹¤í—˜í•´ë´…ì‹œë‹¤!\n",
    "# --------------------------- #\n",
    "x = np.array([1,10,1,1,1])\n",
    "p = 5\n",
    "# --------------------------- #\n",
    "\n",
    "norm_x = np.linalg.norm(x, ord=p)\n",
    "making_norm = (sum(x**p))**(1/p)\n",
    "print(\"result of numpy package norm function : %0.5f \"%norm_x) \n",
    "print(\"result of making norm : %0.5f \"%making_norm)"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9e854f97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.603379Z",
     "start_time": "2024-05-24T08:40:24.599247Z"
    }
   },
   "source": [
    "x = np.array([1,10,1,1,1])\n",
    "p = 19\n",
    "\n",
    "norm_x = np.linalg.norm(x, ord=p)\n",
    "making_norm = (sum(x**p))**(1/p)\n",
    "print(\"result of numpy package norm function : %0.5f \"%norm_x) \n",
    "print(\"result of making norm : %0.5f \"%making_norm)"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9fd7e6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.606310Z",
     "start_time": "2024-05-24T08:40:24.604086Z"
    }
   },
   "source": [
    "sum(x**p)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "62c70f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.611744Z",
     "start_time": "2024-05-24T08:40:24.606910Z"
    }
   },
   "source": [],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "04732c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.617899Z",
     "start_time": "2024-05-24T08:40:24.615839Z"
    }
   },
   "source": [
    "norm_x = np.linalg.norm(x, ord=np.inf)\n",
    "print(\"result of infinite norm : %0.5f \"%norm_x)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9cad1f24",
   "metadata": {},
   "source": [
    "### Matrix norm\n",
    "í–‰ë ¬ì˜ normì˜ ê²½ìš°ëŠ” ë²¡í„°ì™€ ì¡°ê¸ˆ ë‹¤ë¥´ë©°, ì£¼ë¡œ $p=1,\\infty$ ì¸ ê²½ìš°ë§Œ ì•Œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ \n",
    "AëŠ” m X n í–‰ë ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "$$ \\left\\| x\\right\\|_1 := \\underset{1\\leq j\\leq n }{max}\\sum_{i=1}^{m}\\left| a_{ij}\\right| $$\n",
    "\n",
    "$$ \\left\\| x\\right\\|_\\infty := \\underset{1\\leq j\\leq m }{max}\\sum_{j=1}^{n}\\left| a_{ij}\\right| $$\n",
    "\n",
    "p=1ì¸ ê²½ìš°ì—ëŠ” ì»¬ëŸ¼(column)ì˜ í•©ì´ ê°€ì¥ í° ê°’ì´ ì¶œë ¥ë˜ê³ , \n",
    "$p=\\infty$ì¸ ê²½ìš°ì—ëŠ” ë¡œìš°(row)ì˜ í•©ì´ ê°€ì¥ í° ê°’ì´ ì¶œë ¥ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "a7ab0dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:24.620762Z",
     "start_time": "2024-05-24T08:40:24.618554Z"
    }
   },
   "source": [
    "A = np.array([[1,2,3], [1,2,3], [4,6,8]])\n",
    "\n",
    "one_norm_A = np.linalg.norm(A, ord=1)\n",
    "print(\"result one norm of A :\", one_norm_A)\n",
    "\n",
    "inf_norm_A = np.linalg.norm(A, ord=np.inf)\n",
    "print(\"result inf norm of A :\", inf_norm_A)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0201ebd7",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "ë“œë¡­ì•„ì›ƒ(Dropout) ê¸°ë²•ì€ 2014ë…„ë„ì— ë‚˜ì˜¨ ë…¼ë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ë…¼ë¬¸ ì œëª© : Dropout: A Simple Way to Prevent Neural Networks from Overfitting\n",
    "    ë…¼ë¬¸ ë°œí‘œ ì‹œì  : 2014ë…„\n",
    "    ë…¼ë¬¸ ë§í¬ : https://jmlr.org/papers/v15/srivastava14a.html\n",
    "\n",
    "ë“œë¡­ì•„ì›ƒ ê¸°ë²•ì´ ë‚˜ì˜¤ê¸° ì „ì˜ ì‹ ê²½ë§ì€ fully connected architectureë¡œ ëª¨ë“  ë‰´ëŸ°ë“¤ì´ ì—°ê²°ë˜ì–´ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë“œë¡­ì•„ì›ƒì´ë€ í™•ë¥ ì ìœ¼ë¡œ ëœë¤í•˜ê²Œ ëª‡ ê°€ì§€ì˜ ë‰´ëŸ°ë§Œ ì„ íƒí•˜ì—¬ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¦„ ê·¸ëŒ€ë¡œ ëª‡ ê°€ì§€ì˜ ê°’ë“¤ì„ ëª¨ë“  ë‰´ëŸ°ì— ì „ë‹¬í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ, í™•ë¥ ì ìœ¼ë¡œ ë²„ë¦¬ë©´ì„œ ì „ë‹¬í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ë“œë¡­ì•„ì›ƒì€ ì˜¤ë²„í”¼íŒ…ì„ ë§‰ëŠ” regularization layer ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. í™•ë¥ ì„ ë„ˆë¬´ ë†’ì´ë©´ (ë¹„í™œì„±í™”ëœ ë‰´ëŸ°ì˜ ë¹„ì¤‘ì„ ë†’ì´ë©´) ëª¨ë¸ ì•ˆì—ì„œ ê°’ë“¤ì´ ì œëŒ€ë¡œ ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šê³ , í™•ë¥ ì„ ë„ˆë¬´ ë‚®ì¶”ëŠ” ê²½ìš°ì—ëŠ” fully connected layerì™€ ê°™ì´ ë™ì‘í•©ë‹ˆë‹¤. fully connected layerì—ì„œ ì˜¤ë²„í”¼íŒ…ì´ ìƒê¸°ëŠ” ê²½ìš°ì— ì£¼ë¡œ dropout layerë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì½”ë“œëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤. ë…¼ë¬¸ì´ ë‚˜ì˜¨ ì§€ë„ ì˜¤ë˜ë˜ì—ˆê¸° ë•Œë¬¸ì—, ì—¬ëŸ¬ í”„ë ˆì„ì›Œí¬ì—ì„œ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ë˜ì–´ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- https://keras.io/api/layers/regularization_layers/dropout/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32fe35",
   "metadata": {},
   "source": [
    "### ì‹¤ìŠµ (not overfitting)\n",
    "\n",
    "fashion mnistë¼ëŠ” ë°ì´í„° ì…‹ì„ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµì„ ì‹œí‚¤ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ ì´ 10ê°œì˜ í´ë˜ìŠ¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ë°ì´í„°ê°€ ê°„ë‹¨í•œ í¸ì´ê¸°ë„ í•˜ì—¬ 5 epoch ì •ë„ë§Œ í•™ìŠµì‹œì¼œë„ ì–´ëŠ ì •ë„ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤. ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ë¥¼ ì¤‘ê°„ì— ì¶”ê°€í•˜ì—¬ í™•ë¥ ì„ 1ì— ê°€ê¹ê²Œ ì£¼ë©´ ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "3bb9a99a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:28.181690Z",
     "start_time": "2024-05-24T08:40:24.621679Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "print('=3')"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4595d0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:40:28.540938Z",
     "start_time": "2024-05-24T08:40:28.182598Z"
    }
   },
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ce88ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:41:21.822147Z",
     "start_time": "2024-05-24T08:40:28.541977Z"
    }
   },
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # ì—¬ê¸°ì— dropout layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ì•„ë˜ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "    keras.layers.Dropout(0.9),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(train_images, train_labels, epochs=5)"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7c6ac737",
   "metadata": {},
   "source": [
    "dropoutì´ ì—†ì„ ë•Œ ì‹¤ìŠµì„ í•´ë³´ë©´, 5 epoch ì •ë„ë§Œ ëŒë ¤ë„ ì¶©ë¶„íˆ ë†’ì€ ì •í™•ë„ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "7fa70bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:42:08.244714Z",
     "start_time": "2024-05-24T08:41:21.823956Z"
    }
   },
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # ì´ë²ˆì—ëŠ” dropout layerê°€ ì—†ìŠµë‹ˆë‹¤. \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5)"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6ab35fc2",
   "metadata": {},
   "source": [
    "í˜„ì¬ ì´ ë°ì´í„° ì…‹ì€ í•™ìŠµì´ ì˜ ë˜ëŠ” ë°ì´í„° ì…‹ìœ¼ë¡œ, fully connected layerì—ì„œë„ ê²°ê³¼ê°€ ì˜ ë‚˜ì˜´ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë°ìš”. ì¼ë¶€ëŸ¬ ì¤‘ê°„ì— dropout layerë¥¼ ì¶”ê°€í•˜ì—¬ 0.9ì˜ í™•ë¥  ê°’ì„ ì£¼ë‹ˆ í•™ìŠµì´ ì•ˆ ë¨ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ overfittingì´ ë‚˜ëŠ” í™˜ê²½ì—ì„œ dropoutì˜ ì¤‘ìš”ì„±ì„ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì‹¤ìŠµ (overfitting)\n",
    "overfittingì´ ë˜ëŠ”ì§€ í™•ì¸í•´ ë³´ë ¤ë©´ train setê³¼ validation setì˜ loss functionì„ ê·¸ë ¤ë³´ëŠ” ê²ƒì´ ê°€ì¥ ì²« ë²ˆì§¸ ì‹œë„ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ìœ„ì˜ ë°ì´í„°ë¥¼ ì´ì œ train:valid=99:1ì˜ ë¹„ìœ¨ë¡œ ë‚˜ëˆˆ ë’¤ì— loss functionì˜ ê°’ì„ ê·¸ë ¤ë³´ê³ , overfittingì´ ìƒê¸°ëŠ” fully connected layerë¥¼ ë§Œë“¤ì–´ë³´ë„ë¡ í•©ì‹œë‹¤. overfittingì´ ë˜ê²Œ í•˜ê¸° ìœ„í•´ ì˜ë„ì ìœ¼ë¡œ train setì„ 99%ë¡œ ëŠ˜ë¦¬ê³  validation setì„ ì¤„ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    ">### í•™ìŠµíŒ    \n",
    "> ì•„ë˜ ì½”ë“œëŠ” 200 epochì´ë¯€ë¡œ ì½”ë“œê°€ ëŒì•„ê°€ëŠ”ë° 5ë¶„ì´ìƒ ì†Œìš”ë©ë‹ˆë‹¤. ê·¸ë™ì•ˆ overfittingì— ëŒ€í•œ ìë£Œë¥¼ ì°¾ì•„ë³´ë©´ì„œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "id": "39011d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:45:03.219041Z",
     "start_time": "2024-05-24T08:42:08.246283Z"
    }
   },
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_images, train_labels, test_size=0.01, random_state=101)\n",
    "X_train = X_train / 255.0\n",
    "X_valid = X_valid / 255.0\n",
    "\n",
    "# Dense layerë§Œìœ¼ë¡œ ë§Œë“¤ì–´ ë‚¸ classification ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=512, validation_data=(X_valid, y_valid))"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8ad35aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:45:03.403374Z",
     "start_time": "2024-05-24T08:45:03.221726Z"
    }
   },
   "source": [
    "# loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('Loss graph without dropout layer') \n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c97b900b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:45:03.534848Z",
     "start_time": "2024-05-24T08:45:03.408798Z"
    }
   },
   "source": [
    "# accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "y_vacc = history.history['val_accuracy']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vacc, marker='.', c='red', label=\"Validation-set accuracy\")\n",
    "plt.plot(x_len, y_acc, marker='.', c='blue', label=\"Train-set accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.ylim(0.5,1) \n",
    "plt.title('Accuracy graph without dropout layer') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9d664d",
   "metadata": {},
   "source": [
    "dropout layerê°€ ì—†ëŠ” fully connected layerì—ì„œ 200ë²ˆ ì •ë„ì˜ í•™ìŠµì„ í•˜ë‹ˆ train setì˜ accuracyëŠ” ì˜¬ë¼ê°€ê³ , lossëŠ” ì ì  ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ validation setì˜ accuracyì™€ lossëŠ” ì–´ëŠ ì •ë„ ê°’ì—ì„œ ìˆ˜ë ´í•¨ì„ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "ì´ë ‡ê²Œ ì˜¤ë²„í”¼íŒ…ì„ ë§Œë“  í™˜ê²½ì—ì„œ dropout layerë¥¼ ì¶”ê°€í•œ ë’¤ ë‚˜ë¨¸ì§€ í™˜ê²½ì€ ê°™ê²Œ í•œ ì‹¤í—˜ì„ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "1b3dac19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:06.571580Z",
     "start_time": "2024-05-24T08:45:03.536475Z"
    }
   },
   "source": [
    "# Q. dropout layerë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”. (dropout í™•ë¥ ì€ 0.5ë¡œ ì§€ì •í•´ì£¼ì„¸ìš”.)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    # ì—¬ê¸°ì— dropout layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ìœ„ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤. \n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=512, validation_data=(X_valid, y_valid))"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0445845f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:06.712780Z",
     "start_time": "2024-05-24T08:48:06.572850Z"
    }
   },
   "source": [
    "# Q. loss ê°’ì˜ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë´…ì‹œë‹¤.\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.title('Loss graph with dropout layer') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "014e5992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:06.826057Z",
     "start_time": "2024-05-24T08:48:06.713542Z"
    }
   },
   "source": [
    "# Q. accuracy ê°’ì˜ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë´…ì‹œë‹¤. \n",
    "y_vacc = history.history['val_accuracy']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vacc, marker='.', c='red', label=\"Validation-set accuracy\")\n",
    "plt.plot(x_len, y_acc, marker='.', c='blue', label=\"Train-set accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.ylim(0.5,1) \n",
    "plt.title('Accuracy graph with dropout layer') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e6badfd",
   "metadata": {},
   "source": [
    "ì¢‹ì€ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì˜¤ë²„í”¼íŒ…ì„ ë§Œë“œëŠ” í™˜ê²½ì´ ì¡°ê¸ˆ ì–´ë µê¸´ í–ˆì§€ë§Œ, dropout layer í•˜ë‚˜ë§Œìœ¼ë¡œë„ ì˜¤ë²„í”¼íŒ…ì„ ë§‰ê³ , ë‘ ë°ì´í„° ì…‹ì´ ì •í™•ë„ë„ ë¹„ìŠ·í•˜ê²Œ ë‚˜ì˜´ì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤. ì‚¬ì‹¤ ë” ë³µì¡í•œ ë„¤íŠ¸ì›Œí¬ë‚˜, ë” ì–´ë ¤ìš´ ë°ì´í„°ì˜ ê²½ìš°ì—ëŠ” ì´ëŸ¬í•œ ì˜¤ë²„í”¼íŒ…ì´ ë” ìì£¼ ìˆëŠ” ì¼ì´ë¯€ë¡œ, dropout layerë¥¼ ì¶”ê°€í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ë˜í•œ í™•ë¥  ê°’ì´ íŒŒë¼ë¯¸í„°ë¡œ ë“¤ì–´ê°€ë¯€ë¡œ, ì–´ë– í•œ ê°’ì„ ì„ íƒí•˜ëŠëƒëŠ” ë°ì´í„°ì™€ ë„¤íŠ¸ì›Œí¬ì— ë”°ë¼ ë‹¬ë¦° ì¼ì…ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43b9aa",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "    ë…¼ë¬¸ ì œëª© : Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n",
    "    ë…¼ë¬¸ ë°œí‘œ ì‹œì  : 2015ë…„\n",
    "    ë…¼ë¬¸ ë§í¬ : ë…¼ë¬¸ PDF\n",
    "        \n",
    "(__batch normalization__ê³¼ internal covariate shiftê°€ ì—°ê´€ì„±ì´ ì—†ë‹¤ëŠ” ë°˜ë¡ ë„ ìˆê¸° ë•Œë¬¸ì—, \"ì´ëŸ° ì´ì•¼ê¸°ë„ ìˆêµ¬ë‚˜~\" í•˜ê³  ë°›ì•„ë“¤ì´ì‹œë©´ ë©ë‹ˆë‹¤.)\n",
    "\n",
    "ë”¥ëŸ¬ë‹ì—ì„œ ê²½ì‚¬ í•˜ê°•ë²•(gradient descent)ìœ¼ë¡œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ, ë°ì´í„°ì…‹ ì „ì²´ë¥¼ ë³¸ ë‹¤ìŒ ì—…ë°ì´íŠ¸í•˜ëŠ” 'Batch Gradient Descent'ì™€ ë°ì´í„° í•˜ë‚˜ë¥¼ ê´€ì°°í•  ë•Œë§ˆë‹¤ ì—…ë°ì´íŠ¸í•˜ëŠ” 'Stochastic Gradient Descent' ë°©ë²•ì´ ìˆì—ˆì£ . ì´ ë‘˜ì˜ ì ˆì¶©ì•ˆì´ ë°”ë¡œ ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ ê°œì˜ mini-batchë¡œ ìª¼ê°  ë‹¤ìŒ í•˜ë‚˜ì˜ batchë¥¼ ì²˜ë¦¬í•  ë•Œë§ˆë‹¤ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” 'Mini-batch Gradient Descent'ì…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì„ mini-batchë¡œ ìª¼ê°œëŠ” ë°©ë²•ì€ í•™ìŠµ ì†ë„ì™€ ì•ˆì •ì„± ëª¨ë‘ë¥¼ ì¡ì•˜ì§€ë§Œ, ë”¥ëŸ¬ë‹ ëª¨ë¸ ì•ˆì—ì„œ ë°ì´í„°ê°€ ì²˜ë¦¬ë˜ë©´ì„œ ì—¬ëŸ¬ ê°œì˜ mini-batchë“¤ ì‚¬ì´ì— ë°ì´í„° ë¶„í¬ì˜ ì°¨ì´ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. (ì´ê²ƒì´ internal covariate shiftë¥¼ ëŒ€ëµì ìœ¼ë¡œ ì„¤ëª…í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.)\n",
    "\n",
    "ë°ì´í„° ë¶„í¬ì˜ ì°¨ì´ê°€ ì¡´ì¬í•œë‹¤ë©´ gradient ê°’ì˜ ì°¨ì´ë„ ìˆì„ ê²ƒì´ê³ , ê°™ì€ learning rate ê°’ì„ ê°€ì§€ê³  ìˆë”ë¼ë„ gradient vanishingì´ë‚˜ gradient explode ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. batch normalization ê¸°ë²•ì€ ê° mini-batchë§ˆë‹¤ í‰ê· ê³¼ ë¶„ì‚°ì„ ê³„ì‚°í•˜ì—¬ ì •ê·œí™”(normalization)ë¥¼ ìˆ˜í–‰í•˜ê³ , `scale and shift` ë³€í™˜ì„ ì ìš©í•˜ì—¬ mini-batchë“¤ì´ ë¹„ìŠ·í•œ ë°ì´í„° ë¶„í¬ë¥¼ ê°€ì§€ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë…¼ë¬¸ì—ì„œ ì„¤ëª…í•œ ì•Œê³ ë¦¬ì¦˜ì„ ì•„ë˜ì— ì ì–´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Input: Values of x over a mini-batch: \n",
    "$B = \\{ x_i, ..., x_m \\}$  Parameters to be learned: $\\gamma,\\beta$\n",
    "\n",
    "Output: \n",
    "$\\{y_i = BN_{\\gamma,\\beta} (x_i)\\}$\n",
    "\n",
    "1. mini-batch mean :\n",
    "$$\\mu_B \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m} x_i$$\n",
    "\n",
    "2. mini-batch variance :\n",
    "$$ \\sigma_B^2 \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m} (x_i - \\mu_B)^2 $$\n",
    "\n",
    "3. normalize :\n",
    "$$ \\hat x_i \\leftarrow \\frac{x_i - \\mu_B}{sqrt(\\sigma_B^2 + \\epsilon)} $$\n",
    "\n",
    "4. scale and shift :\n",
    "$$ y_i \\leftarrow \\gamma \\hat{x_i} + \\beta \\equiv BN_{\\gamma, \\beta}(x_i) $$\n",
    "\n",
    "ìœ„ ìˆ˜ì‹ì„ í’€ì–´ì„œ ì„¤ëª…í•´ ë“œë¦¬ë©´ batch normalizationì€ mini-batchì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ êµ¬í•´ì„œ ì…ë ¥ ë°ì´í„°ë¥¼ ì •ê·œí™”(normalize)í•˜ê³ , ì´ ê°’ì— scale($\\gamma$)ê³¼ shift($\\beta$)ë¥¼ ì¶”ê°€í•œ ê²ƒì…ë‹ˆë‹¤. ê²°êµ­ ì…ë ¥ ë°ì´í„°($x_i$)ëŠ” batch normalizationì„ ê±°ì³ $y_i(=\\gamma \\hat{x_i} + \\beta)$ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "- ì¤‘ê°„ì— $\\epsilon$ì´ ë¶™ì€ ì´ìœ ëŠ” ë¶„ì‚°($\\sigma_B^2$)ì´ 0ì¼ ê²½ìš° ë‚˜ëˆ—ì…ˆ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.\n",
    "- $\\gamma$ì™€ $\\beta$ ê°’ì€ í•™ìŠµ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í•™ìŠµì´ ì§„í–‰ë˜ë©´ì„œ ê°€ì¤‘ì¹˜ì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d1732",
   "metadata": {},
   "source": [
    "### ì‹¤ìŠµ\n",
    "ì•„ë¬´ê²ƒë„ í•˜ì§€ ì•Šì€ fully connected layerì™€ batch normalization layerë¥¼ ì¶”ê°€í•œ ë‘ ì‹¤í—˜ì„ ë¹„êµí•˜ê³ ì í•©ë‹ˆë‹¤. ì¤‘ì ì ìœ¼ë¡œ ë´ì•¼ í•  ë‚´ìš©ì€ ì •í™•ë„ ë¹„êµì™€ ì†ë„ì˜ ì°¨ì´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "828c0ef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:06.830328Z",
     "start_time": "2024-05-24T08:48:06.826922Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "print('=3')"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "952ded43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:07.304286Z",
     "start_time": "2024-05-24T08:48:06.830929Z"
    }
   },
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "881cdc40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:13.608045Z",
     "start_time": "2024-05-24T08:48:07.306851Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_images, train_labels, test_size=0.3, random_state=101)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(X_train, y_train, epochs=20, batch_size=2048, validation_data=(X_valid, y_valid))"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "369a5858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:13.716759Z",
     "start_time": "2024-05-24T08:48:13.608931Z"
    }
   },
   "source": [
    "# loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.title('Loss graph without batch normalization') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ],
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "884dc6d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:13.835155Z",
     "start_time": "2024-05-24T08:48:13.717746Z"
    }
   },
   "source": [
    "# accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "y_vacc = history.history['val_accuracy']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vacc, marker='.', c='red', label=\"Validation-set accuracy\")\n",
    "plt.plot(x_len, y_acc, marker='.', c='blue', label=\"Train-set accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.ylim(0.5,1)\n",
    "plt.title('Accuracy graph without batch normalization') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "617a4879",
   "metadata": {},
   "source": [
    "ì•„ë˜ëŠ” BatchNormalization layerë¥¼ ì¶”ê°€í•œ ì‹¤ìŠµì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "id": "4f93954b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:48:21.321582Z",
     "start_time": "2024-05-24T08:48:13.835948Z"
    }
   },
   "source": [
    "# Q. ë‘ ê°œì˜ dense layer ì‚¬ì´ì— batch normalization layerë¥¼ ì¶”ê°€í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # ì—¬ê¸°ì— batch normalization layerë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ layerëŠ” ìœ„ì˜ ì‹¤ìŠµê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model.fit(X_train, y_train, epochs=20, batch_size=2048, validation_data=(X_valid, y_valid))"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "27c156d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:56:34.556047Z",
     "start_time": "2024-05-24T08:56:34.376380Z"
    }
   },
   "source": [
    "# loss ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.ylim(0,1)\n",
    "plt.title('Loss graph without batch normalization') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T08:57:04.598051Z",
     "start_time": "2024-05-24T08:57:04.467068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# accuracy ê°’ì„ plot í•´ë³´ê² ìŠµë‹ˆë‹¤. \n",
    "y_vacc = history.history['val_accuracy']\n",
    "y_acc = history.history['accuracy']\n",
    "x_len = np.arange(len(y_acc))\n",
    "\n",
    "plt.plot(x_len, y_vacc, marker='.', c='red', label=\"Validation-set accuracy\")\n",
    "plt.plot(x_len, y_acc, marker='.', c='blue', label=\"Train-set accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.ylim(0.5,1)\n",
    "plt.title('Accuracy graph without batch normalization') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ],
   "id": "71552c52ada33dc3",
   "execution_count": 43,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Q. L1 regularizationê³¼ L2 regularizationì˜ ê³µí†µì ê³¼ ì°¨ì´ì ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?\n",
    "[ê³µí†µì ]\n",
    "ë‘ ë°©ë²• ëª¨ë‘ Lp norm ê°œë…ì„ ì‚¬ìš©í•˜ê³  ìˆê³ , ì˜¤ë²„í”¼íŒ…ì´ ë°œìƒí•˜ì§€ ì•Šë„ë¡ ëª¨ë¸ì— ì œì•½ ì¡°ê±´ì„ ê±¸ì–´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "[ì°¨ì´ì ]\n",
    "L1 regularization(Lasso)ì€ L1 normì„ ì‚¬ìš©í•˜ë©°, ì¼ë¶€ coefficient ê°’ì„ 0ìœ¼ë¡œ ë³´ë‚´ê¸° ë•Œë¬¸ì— ì°¨ì› ì¶•ì†Œì™€ ë¹„ìŠ·í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "L2 regularization(Ridge)ì€ L2 normì„ ì‚¬ìš©í•˜ë©°, ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë³´ë‚´ì§€ëŠ” ì•Šì§€ë§Œ ì œê³± í•­ì´ ìˆê¸° ë•Œë¬¸ì— L1 regularizationë³´ë‹¤ëŠ” ìˆ˜ë ´ ì†ë„ê°€ ë¹ ë¥´ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤."
   ],
   "id": "1b31b182abe10ce0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
