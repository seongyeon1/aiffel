{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590535f7",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감정 분석 문제에 SentencePiece 적용해 보기\n",
    "\n",
    "네이버 영화리뷰 감정 분석 태스크가 있습니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용하게 되는데요.\n",
    "\n",
    "만약 이 문제에서 tokenizer를 SentencePiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? KoNLPy에 있는 Mecab, kkma, Okt 등과 비교해보세요. (여러분들은 fasttext로 사전훈련된 Word Vector를 사용할 수 있지만 sentencepiece와 KoNLPy에 있는 형태소로 모델을 만드는 것보다 코드 수정이 많이 일어납니다. 기본적인 태스크를 끝나고(sentencepiece - KoNLPy 형태소 비교) 도전하시는걸 추천합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821ef04",
   "metadata": {},
   "source": [
    "## 프로젝트: SentencePiece 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01661d58",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import konlpy\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(plt.__version__)\n",
    "print(konlpy.__version__)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "171748ce",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from konlpy.tag import Hannanum,Kkma,Komoran,Mecab,Okt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25079e13",
   "metadata": {},
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cde65de1",
   "metadata": {},
   "source": [
    "import os, re"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "90a6b3c9",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fc72a32",
   "metadata": {},
   "source": [
    "train_path = './data/ratings_train.txt'\n",
    "test_path = './data/ratings_test.txt'\n",
    "\n",
    "\n",
    "train = pd.read_table(train_path)\n",
    "test = pd.read_table(test_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b13e0db",
   "metadata": {},
   "source": [
    "train.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd68b0b",
   "metadata": {},
   "source": [
    "test.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ad258b",
   "metadata": {},
   "source": [
    "print(f\"train shape => {train.shape} \\ntest shape => {test.shape}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ca4832",
   "metadata": {},
   "source": [
    "train.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3627ca8f",
   "metadata": {},
   "source": [
    "## 훈련 데이터 라벨링 값 비율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4331902",
   "metadata": {},
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"label\", data=train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cba8bf00",
   "metadata": {},
   "source": [
    "labels, frequencies = np.unique(train.label.values, return_counts=True)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(frequencies, labels = labels, autopct= '%1.1f%%')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a48f211b",
   "metadata": {},
   "source": [
    "## 훈련, 테스트 데이터 결측치 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f1f7f9",
   "metadata": {},
   "source": [
    "train.isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37321580",
   "metadata": {},
   "source": [
    "test.isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9be02278",
   "metadata": {},
   "source": [
    "train.drop_duplicates(subset=['document'], inplace=True)\n",
    "test.drop_duplicates(subset=['document'], inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7bf969be",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "## 1) train, test data의 문장 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7f34985",
   "metadata": {},
   "source": [
    "train_len = train.document.apply(lambda x: len(x))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2765099",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train_len.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "207aa26c",
   "metadata": {},
   "source": [
    "train_len.hist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33e93455",
   "metadata": {},
   "source": [
    "test.document.apply(lambda x: len(x)).hist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "551bec56",
   "metadata": {},
   "source": [
    "- train len과 test len의 분포를 비교해본 결과 상당히 유사해서 길이를 줄이는 등의 전처리는 진행하지 않는 것이 좋을 것 같았다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340fefcd",
   "metadata": {},
   "source": [
    "## 2) 길이가 너무 길거나 짧은 실제 데이터 확인 \n",
    "\n",
    "- 한글자의 경우도 의미가 없지 않을 까 확인해봤는데 굿, 욜 이런 부분에서 의미가 있는 부분도 있었다\n",
    "- 문자를 다 삭제하는 것도 고민해봐야겠다. ♥,♡,乃, ㅄ 도 의미가 있어보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5deb257e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train.loc[train_len[train_len > 145].index].document"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b392026e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "' '.join(train.loc[train_len[train_len == 1].index].document)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "48d8e67a",
   "metadata": {},
   "source": [
    "- 한글자의 경우도 의미가 없지 않을 까 확인해봤는데 굿, 욜 이런 부분에서 의미가 있는 부분도 있었다\n",
    "- 문자를 다 삭제하는 것도 고민해봐야겠다. ♥,♡,乃, ㅄ 도 의미가 있어보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efcaa3dc",
   "metadata": {},
   "source": [
    "import re"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9cefe336",
   "metadata": {},
   "source": [
    "### 반복되는 문자 처리 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53284828",
   "metadata": {},
   "source": [
    "i = '숨은글씨 찾기 의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리니의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리'\n",
    "\n",
    "re.sub('(\\\\S{2})\\\\1+', '\\\\1', i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67e5cea9",
   "metadata": {},
   "source": [
    "len(train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f9ad7",
   "metadata": {},
   "source": [
    "### 최종 전처리 함수\n",
    "- 한글, 숫자, 초성, ♥♡乃ㄳㅄ의 문자를 남겼다\n",
    "- 초성 ㅜㅜ, ㅋㅋ이 감정의 의미를 담을 수 있다고 파악했기 때문이다\n",
    "- 다중 공백을 제거하는 코드를 추가하였다\n",
    "- ㅋ와 ㅋㅋ은 다르게 인지하였다\n",
    "    - ㅜㅜㅜ, ㅋㅋㅋㅋㅋㅋ 등의 다중 초성은 2개의 초성으로 모두 합쳐주었다\n",
    "- 빈 하트와 채워진 하트는 채워진 하트로 통일하고 하트의 갯수는 모두 하나로 바꿔주었다\n",
    "- 반복되는 문자열은 하나만 남기고 지워줬다"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d71bccf2",
   "metadata": {},
   "source": [
    "def preprocessing(train, col='document'):\n",
    "    train[col] = train[col].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9♥♡乃ㄳㅄ ]\",\"\") # 정규 표현식 수행\n",
    "    train[col] = train[col].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "    train[col].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "    train.dropna(how='any', inplace=True)\n",
    "    \n",
    "    train[col] = train[col].apply(lambda x: ' '.join(x.split()))\n",
    "    train[col] = train[col].apply(lambda x: re.sub(r'(ㅋ|ㅎ|ㅜ|ㅠ){2,}', lambda m: m.group(1) * 2, x)) # 반복되는 2자리 문자 처리\n",
    "\n",
    "    train[col] = train[col].str.replace(r'♡','♥')\n",
    "    train[col] = train[col].apply(lambda x: re.sub(r'♥+', '♥', x))\n",
    "    train[col] = train[col].apply(lambda x: re.sub(r'\\b(\\S+)( \\1)+', r'\\1', x))\n",
    "    \n",
    "    return train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a07ce8f7",
   "metadata": {},
   "source": [
    "train = preprocessing(train, col='document')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0efecf25",
   "metadata": {},
   "source": [
    "train.document[train.document.str.contains('♥|♡')].tolist()[:10]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7eeae2a",
   "metadata": {},
   "source": [
    "train.document.apply(lambda x: len(x)).hist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dac809f7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train.document.apply(lambda x: len(x)).describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2291691b",
   "metadata": {},
   "source": [
    "train_len = train.document.apply(lambda x: len(x))\n",
    "\n",
    "train.loc[train_len[train_len > 135].index].document.tolist()[:10]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3448246b",
   "metadata": {},
   "source": [
    "corpus = train.document.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "98d1bfb3",
   "metadata": {},
   "source": [
    "### 네이버 영화리뷰 감정 분석 코퍼스에 SentencePiece를 적용시킨 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "249bf886",
   "metadata": {},
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-nsmc.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in corpus:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "091105c6",
   "metadata": {},
   "source": [
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02a7304f",
   "metadata": {},
   "source": [
    "sample = '아기자기하고 순수한이런영화좋다♥해피엔딩 결말도굿♥우울했는데 영화보고 힐링♥'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97c1200a",
   "metadata": {},
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds(sample)\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces(sample,1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55379344",
   "metadata": {},
   "source": [
    "## Tokenizer 함수 작성\n",
    "\n",
    "우리는 위에서 훈련시킨 SentencePiece를 활용하여 위 함수와 유사한 기능을 하는 sp_tokenize() 함수를 정의할 겁니다. 하지만 SentencePiece가 동작하는 방식이 단순 토큰화와는 달라 완전히 동일하게는 정의하기 어렵습니다. 그러니 아래 조건을 만족하는 함수를 정의하도록 하습니다.\n",
    "\n",
    "1. 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list 를 전달합니다.\n",
    "\n",
    "1. 생성된 vocab 파일을 읽어와 { <word> : <idx> } 형태를 가지는 word_index 사전과 { <idx> : <word>} 형태를 가지는 index_word 사전을 생성하고 함께 반환합니다.\n",
    "\n",
    "1. 리턴값인 tensor 는 앞의 함수와 동일하게 토큰화한 후 Encoding된 문장입니다. 바로 학습에 사용할 수 있게 Padding은 당연히 해야겠죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28121773",
   "metadata": {},
   "source": [
    "### 학습된 모델로 sp_tokenize() 메소드 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beb0e586",
   "metadata": {},
   "source": [
    "test = preprocessing(test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d25e649",
   "metadata": {},
   "source": [
    "test_data = test.document.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a05affe4",
   "metadata": {},
   "source": [
    "import re"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1a64024",
   "metadata": {},
   "source": [
    "def sp_tokenize(s, corpus): \n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    " \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    #tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ea99325",
   "metadata": {},
   "source": [
    "tensor, word_index, index_word = sp_tokenize(s, corpus)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9ca4d01",
   "metadata": {},
   "source": [
    "num_tokens = [len(tokens) for tokens in tensor]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 평균값, 최댓값, 표준편차\n",
    "print(f\"토큰 길이 평균: {np.mean(num_tokens)}\")\n",
    "print(f\"토큰 길이 최대: {np.max(num_tokens)}\")\n",
    "print(f\"토큰 길이 표준편차: {np.std(num_tokens)}\")\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(f'설정 최대 길이: {maxlen}')\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 설정값인 {maxlen}에 포함됩니다.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f630bdd",
   "metadata": {},
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af3a5ff5",
   "metadata": {},
   "source": [
    "max_len = 60\n",
    "below_threshold_len(max_len, tensor)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "055cfd86",
   "metadata": {},
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen=60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d674bfd",
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb66f1d2",
   "metadata": {},
   "source": [
    "train.label.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "761a4317",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5df5b9e",
   "metadata": {},
   "source": [
    "y = train['label']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3813a96b",
   "metadata": {},
   "source": [
    "y.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8e452c0",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "# X_train = preprocess_data(X_train, sp)\n",
    "# X_test = preprocess_data(X_test, sp)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a7e29c11",
   "metadata": {},
   "source": [
    "# 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755bb228",
   "metadata": {},
   "source": [
    "- 모델 선정 이유\n",
    "    >- 기존에 네이버 리뷰 프로젝트와 똑같이 모델을 사용하여 같은 환경에서 토큰에 따라 성능이 어떻게 변화할 수 있는지 확인하기 위해 같은 모델을 사용하였다.\n",
    "    >- 시계열에서 좋은 성능을 가지는 lstm, stacked lstm, 1d cnn 모델을 테스트하였다. \n",
    "\n",
    "- Metrics 선정 이유\n",
    "    >- 데이터 label 분포를 확인해본결과 거의 반반으로 분포해 있어서 acc를 사용하였다\n",
    "\n",
    "- Loss 선정 이유\n",
    "    >- 긍정, 부정을 분류하는 task이기에 binary_crossentropy 를 사용하였다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d7e4b",
   "metadata": {},
   "source": [
    "### LSTM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cbcd77f",
   "metadata": {},
   "source": [
    "# 모델 설계\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c530871c",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8770b5c7",
   "metadata": {},
   "source": [
    "# 모델 검증\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_lstm_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fe29289",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f0cead92",
   "metadata": {},
   "source": [
    "def draw_graph(history):\n",
    "    history_dict = history.history\n",
    "    try:\n",
    "        acc = history_dict['accuracy']\n",
    "        val_acc = history_dict['val_accuracy']\n",
    "    except:\n",
    "        acc = history_dict['acc']\n",
    "        val_acc = history_dict['val_acc']\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6d0157a6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2df0e4ca",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d4e936b",
   "metadata": {},
   "source": [
    "def predict_x(s, corpus):\n",
    "    \n",
    "    tensor = []\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen=42)\n",
    "\n",
    "    return tensor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96047704",
   "metadata": {},
   "source": [
    "X_test = predict_x(s, test.document.tolist())\n",
    "y_test = test.label"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db1a6c3b",
   "metadata": {},
   "source": [
    "loaded_model = load_model('best_lstm_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "14b12ccf",
   "metadata": {},
   "source": [
    "# stacked lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7a941ee",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "def create_model(vocab_size, word_vector_dim):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, word_vector_dim, input_shape=(None,)),\n",
    "        LSTM(8, return_sequences=True),\n",
    "        LSTM(16, return_sequences=False),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "vocab_size = len(s)  # SentencePiece의 vocab size\n",
    "word_vector_dim = 300\n",
    "stacked_lstm_model = create_model(vocab_size, word_vector_dim)\n",
    "stacked_lstm_model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "459e68a0",
   "metadata": {},
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('stacked_lstm_best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "32031b01",
   "metadata": {},
   "source": [
    "stacked_lstm_history = stacked_lstm_model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0b056ff1",
   "metadata": {},
   "source": [
    "draw_graph(stacked_lstm_history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb4ffe53",
   "metadata": {},
   "source": [
    "loaded_model = load_model('stacked_lstm_best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e506a337",
   "metadata": {},
   "source": [
    "## 모델링 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18894c60",
   "metadata": {},
   "source": [
    "embedding_dim = 256 # 임베딩 벡터의 차원\n",
    "dropout_ratio = 0.5 # 드롭아웃 비율\n",
    "num_filters = 256 # 커널의 수\n",
    "kernel_size = 3 # 커널의 크기\n",
    "hidden_units = 128 # 뉴런의 수\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(vocab_size, embedding_dim))\n",
    "cnn_model.add(Dropout(dropout_ratio))\n",
    "cnn_model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(hidden_units, activation='relu'))\n",
    "cnn_model.add(Dropout(dropout_ratio))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint('cnn_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "cnn_model.summary()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dce2a193",
   "metadata": {},
   "source": [
    "cnn_history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef6ddc61",
   "metadata": {},
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "004072aa",
   "metadata": {},
   "source": [
    "draw_graph(cnn_history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fdbac858",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "loaded_model = load_model('cnn_best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2617e0bf",
   "metadata": {},
   "source": [
    "## Sentence Piece 결과 정리 (test acc 기준)\n",
    "- lstm model : 0.8601\n",
    "- stacked lstm model : 0.8517\n",
    "- 1d cnn model : 0.8557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a606754",
   "metadata": {},
   "source": [
    "## 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정 분석 모델을 재학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efba2ed",
   "metadata": {},
   "source": [
    "# KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6f623",
   "metadata": {},
   "source": [
    "- 꼬꼬마(kkma)는 java 용량 문제 및 속도가 너무 느려서 수많은 시도 끝에 테스트하기 어렵다는 판단을 내렸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b64616c4",
   "metadata": {},
   "source": [
    "hannanum = Hannanum()\n",
    "kkma = Kkma(max_heap_size=2048)\n",
    "komoran = Komoran()\n",
    "mecab = Mecab()\n",
    "okt = Okt()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb1f6e53",
   "metadata": {},
   "source": [
    "tokenizer_list = [hannanum, kkma, komoran, mecab, okt]\n",
    "\n",
    "# kor_text = '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네'\n",
    "kor_text = '노래도 너무즐겁고 내용도 아기자기 귀여워요동화같은ㅠ근데 아이들 너무귀엽다♥'\n",
    "\n",
    "for tokenizer in tokenizer_list:\n",
    "    print('[{}] \\n{}'.format(tokenizer.__class__.__name__, tokenizer.pos(kor_text)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1083ddc",
   "metadata": {},
   "source": [
    "# kkma_doc = train.document.progress_apply(lambda x: kkma.pos(x)).tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9541027f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea65abf9",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenizer_list = [hannanum, komoran, mecab, okt]\n",
    "\n",
    "for tokenizer in tokenizer_list:\n",
    "    name = str(tokenizer.__class__.__name__)\n",
    "    print(f'[{name}]')\n",
    "    \n",
    "    if name not in train.columns:\n",
    "        train[f'{name}'] = train.document.progress_apply(lambda x: tokenizer.morphs(x))\n",
    "    \n",
    "        if name == 'Okt':\n",
    "            train[f'{name}_stem'] = train.document.progress_apply(lambda x: tokenizer.morphs(x, stem=True))\n",
    "        \n",
    "        train.to_csv('data_preprocessed_morph_final.csv', index=False)\n",
    "    else:\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ff84a96",
   "metadata": {},
   "source": [
    "train.to_csv('data_preprocessed_morph_final.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6663ca02",
   "metadata": {},
   "source": [
    "train.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5270aaa5",
   "metadata": {},
   "source": [
    "## 형태소 분석기 별 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43887c75",
   "metadata": {},
   "source": [
    "test = preprocessing(test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb6a3ea5",
   "metadata": {},
   "source": [
    "tokenizer_list = [hannanum, komoran, mecab, okt]\n",
    "\n",
    "for tokenizer in tokenizer_list:\n",
    "    name = str(tokenizer.__class__.__name__)\n",
    "    print(f'[{name}]')\n",
    "    \n",
    "    if name not in test.columns:\n",
    "        test[f'{name}'] = test.document.progress_apply(lambda x: tokenizer.morphs(x))\n",
    "    \n",
    "        if name == 'Okt':\n",
    "            test[f'{name}_stem'] = test.document.progress_apply(lambda x: tokenizer.morphs(x, stem=True))\n",
    "        \n",
    "        test.to_csv('test_data_preprocessed_morph_final.csv', index=False)\n",
    "    else:\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "253141e0",
   "metadata": {},
   "source": [
    "tokenizer_list"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d93ef338",
   "metadata": {},
   "source": [
    "train.head(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8939fa32",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7f5f875",
   "metadata": {},
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자',\n",
    "             '에','와','한','하다','하','어','다','네','요','에서','에게','게','ㄴ','에서','고','로']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2765edb8",
   "metadata": {},
   "source": [
    "def compare_morphs(df, test, tokenizer, stopwords=stopwords):\n",
    "    \n",
    "    col = tokenizer.__class__.__name__\n",
    "\n",
    "    X_data = df[col].apply(lambda x: [str(i) for i in x]).dropna().tolist()\n",
    "    y_data = df['label'].dropna()\n",
    "\n",
    "    print(len(X_data), len(y_data))\n",
    "    \n",
    "    # 형태소 분석\n",
    "    #test_morphs = test.document.progress_apply(lambda x: tokenizer.morphs(x))\n",
    "    test_morphs = test[col].copy()\n",
    "    test_morphs = test_morphs.progress_apply(lambda x: [str(word) for word in x if not word in stopwords])\n",
    "\n",
    "    # 토큰화\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_data)\n",
    "\n",
    "    print(len(tokenizer.word_index))\n",
    "\n",
    "    # 등장 빈도수가 3회 미만인 단어들의 분포 확인\n",
    "\n",
    "    threshold = 3\n",
    "    total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "    rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "    total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "    rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "    # 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "    for key, value in tokenizer.word_counts.items():\n",
    "        total_freq = total_freq + value\n",
    "\n",
    "        # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "        if(value < threshold):\n",
    "            rare_cnt = rare_cnt + 1\n",
    "            rare_freq = rare_freq + value\n",
    "\n",
    "    print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "    print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "    print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "    print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "    # 등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한\n",
    "    # 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "    # 0번 패딩 토큰을 고려하여 + 1\n",
    "\n",
    "    vocab_size = total_cnt - rare_cnt + 1\n",
    "    print('단어 집합의 크기 :',vocab_size)\n",
    "\n",
    "    # 이를 케라스 토크나이저의 인자로 넘겨 텍스트 시퀀스를 숫자 시퀀스로 변환\n",
    "    \n",
    "    tokenizer = Tokenizer(vocab_size) \n",
    "    tokenizer.fit_on_texts(X_data)\n",
    "    X_train = tokenizer.texts_to_sequences(X_data)\n",
    "    X_test = tokenizer.texts_to_sequences(test_morphs)\n",
    "    \n",
    "    return X_train, X_test, tokenizer, vocab_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65f6d87c",
   "metadata": {},
   "source": [
    "X_train, X_test, tokenizer, vocab_size = compare_morphs(train, test, okt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1201504",
   "metadata": {},
   "source": [
    "y_train = y_data.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed5e2e7c",
   "metadata": {},
   "source": [
    "len(X_train), len(y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05eae88e",
   "metadata": {},
   "source": [
    "def drop_empty_list(X_train, y_train):\n",
    "    # 각 샘플들의 길이를 확인해서 길이가 0인 샘플들의 인덱스 받아오기\n",
    "    drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "    print(f'빈 샘플 수 : {len(drop_train)}')\n",
    "\n",
    "    # 빈 샘플 제거\n",
    "    X_train = np.delete(X_train, drop_train, axis=0)\n",
    "    y_train = np.delete(y_train, drop_train, axis=0)\n",
    "    print(f'빈 샘플 제거 후 남은 X train data : {len(X_train)}')\n",
    "    print(f'빈 샘플 제거 후 남은 y train data : {len(y_train)}')\n",
    "    return X_train, y_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "776626db",
   "metadata": {},
   "source": [
    "X_train, y_train = drop_empty_list(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6ed29d7",
   "metadata": {},
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cc1819f",
   "metadata": {},
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5feca83f",
   "metadata": {},
   "source": [
    "max_len = 50\n",
    "below_threshold_len(max_len, X_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4cc0db87",
   "metadata": {},
   "source": [
    "def padding_and_split(X_train, X_test, y_train, max_len):\n",
    "    X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "    X_test = pad_sequences(X_test, maxlen = max_len)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True,\n",
    "                                                      stratify=y_train, random_state=777)\n",
    "    return X_train, X_val, y_train, y_val, X_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "90b6dd50",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val, X_test = padding_and_split(X_train, X_test, y_train, max_len)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6553d96",
   "metadata": {},
   "source": [
    "vocab_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "391e73b7",
   "metadata": {},
   "source": [
    "embedding_dim = 100"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9b02ed91",
   "metadata": {},
   "source": [
    "def lstm_model(vocab_size, embedding_dim, optimizer='rmsprop'):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim),\n",
    "        LSTM(128),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f57d8563",
   "metadata": {},
   "source": [
    "model = lstm_model(vocab_size, embedding_dim)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16a755ae",
   "metadata": {},
   "source": [
    "# 모델 검증\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_lstm_model_okt.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b9947956",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca4eae9a",
   "metadata": {},
   "source": [
    "def draw_graph(history):\n",
    "    history_dict = history.history\n",
    "    try:\n",
    "        acc = history_dict['accuracy']\n",
    "        val_acc = history_dict['val_accuracy']\n",
    "    except:\n",
    "        acc = history_dict['acc']\n",
    "        val_acc = history_dict['val_acc']\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b87247",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9bbd78b3",
   "metadata": {},
   "source": [
    "X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "97b841df",
   "metadata": {},
   "source": [
    "y_test = np.array(test.label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad46a053",
   "metadata": {},
   "source": [
    "# 테스트 정확도 측정\n",
    "\n",
    "loaded_model = load_model('best_lstm_model_okt.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "05281ebc",
   "metadata": {},
   "source": [
    "## 한나눔 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7dc40463",
   "metadata": {},
   "source": [
    "X_train, X_test, tokenizer, vocab_size = compare_morphs(train, test, hannanum)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "898ac148",
   "metadata": {},
   "source": [
    "y_train = y_data.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "266563c4",
   "metadata": {},
   "source": [
    "X_train, y_train = drop_empty_list(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d08bc87f",
   "metadata": {},
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2bcc9cb6",
   "metadata": {},
   "source": [
    "max_len = 50\n",
    "below_threshold_len(max_len, X_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c332f8d",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val, X_test = padding_and_split(X_train, X_test, y_train, max_len)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf8b7b52",
   "metadata": {},
   "source": [
    "embedding_dim = 100"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b2e14c7",
   "metadata": {},
   "source": [
    "model = lstm_model(vocab_size, embedding_dim)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d246c213",
   "metadata": {},
   "source": [
    "# 모델 검증\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_lstm_model_hannanum.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52bc5058",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e500d214",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "40c49af2",
   "metadata": {},
   "source": [
    "X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "293fdb3a",
   "metadata": {},
   "source": [
    "y_test = np.array(test.label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3617f76f",
   "metadata": {},
   "source": [
    "y_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fae597ce",
   "metadata": {},
   "source": [
    "# 테스트 정확도 측정\n",
    "\n",
    "loaded_model = load_model('best_lstm_model_hannanum.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3acadf91",
   "metadata": {},
   "source": [
    "## Komoran 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "325ca14f",
   "metadata": {},
   "source": [
    "name = komoran.__class__.__name__.lower()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "03f2127d",
   "metadata": {},
   "source": [
    "X_train, X_test, tokenizer, vocab_size = compare_morphs(train, test, komoran)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "200abbbc",
   "metadata": {},
   "source": [
    "y_train = y_data.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "70447a13",
   "metadata": {},
   "source": [
    "X_train, y_train = drop_empty_list(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "850ab8a5",
   "metadata": {},
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fc65b4ab",
   "metadata": {},
   "source": [
    "max_len = 70\n",
    "below_threshold_len(max_len, X_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3619ee49",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val, X_test = padding_and_split(X_train, X_test, y_train, max_len)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bb3d4cca",
   "metadata": {},
   "source": [
    "embedding_dim = 100"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1a2be0c9",
   "metadata": {},
   "source": [
    "model = lstm_model(vocab_size, embedding_dim)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "556c4a56",
   "metadata": {},
   "source": [
    "# 모델 검증\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'best_lstm_model_{name}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b8773c98",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "04f93c2e",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d1f116a0",
   "metadata": {},
   "source": [
    "X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "938a52dc",
   "metadata": {},
   "source": [
    "y_test = np.array(test.label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c5fb14d",
   "metadata": {},
   "source": [
    "y_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "baf813a5",
   "metadata": {},
   "source": [
    "# 테스트 정확도 측정\n",
    "\n",
    "loaded_model = load_model(f'best_lstm_model_{name}.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ad0df21d",
   "metadata": {},
   "source": [
    "# Mecab 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c92b4c53",
   "metadata": {},
   "source": [
    "name = mecab.__class__.__name__.lower()\n",
    "\n",
    "X_train, X_test, tokenizer, vocab_size = compare_morphs(train, test, mecab)\n",
    "y_train = y_data.tolist()\n",
    "X_train, y_train = drop_empty_list(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9270555d",
   "metadata": {},
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "73637e31",
   "metadata": {},
   "source": [
    "max_len = 70\n",
    "below_threshold_len(max_len, X_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "16d4ecf9",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val, X_test = padding_and_split(X_train, X_test, y_train, max_len)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b3875b3b",
   "metadata": {},
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = lstm_model(vocab_size, embedding_dim)\n",
    "\n",
    "# 모델 검증\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'best_lstm_model_{name}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7e209f44",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "242d8bf5",
   "metadata": {},
   "source": [
    "X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4bc5bba6",
   "metadata": {},
   "source": [
    "y_test = np.array(test.label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "211b44ee",
   "metadata": {},
   "source": [
    "y_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f147e349",
   "metadata": {},
   "source": [
    "# 테스트 정확도 측정\n",
    "\n",
    "loaded_model = load_model(f'best_lstm_model_{name}.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "81ebb487",
   "metadata": {},
   "source": [
    "## Okt (stem=True) 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "389630d5",
   "metadata": {},
   "source": [
    "df = train.copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "10fd308b",
   "metadata": {},
   "source": [
    "col = 'Okt_stem'\n",
    "name = col.lower()\n",
    "\n",
    "X_data = df[col].apply(lambda x: [str(i) for i in x]).dropna().tolist()\n",
    "y_data = df['label'].dropna()\n",
    "\n",
    "print(len(X_data), len(y_data))\n",
    "\n",
    "# 형태소 분석\n",
    "#test_morphs = test.document.progress_apply(lambda x: tokenizer.morphs(x))\n",
    "test_morphs = test[col].copy()\n",
    "test_morphs = test_morphs.progress_apply(lambda x: [str(word) for word in x if not word in stopwords])\n",
    "\n",
    "# 토큰화\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_data)\n",
    "\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "# 등장 빈도수가 3회 미만인 단어들의 분포 확인\n",
    "\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "# 등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)\n",
    "\n",
    "# 이를 케라스 토크나이저의 인자로 넘겨 텍스트 시퀀스를 숫자 시퀀스로 변환\n",
    "\n",
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_data)\n",
    "X_train = tokenizer.texts_to_sequences(X_data)\n",
    "X_test = tokenizer.texts_to_sequences(test_morphs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ddfa560d",
   "metadata": {},
   "source": [
    "y_train = y_data.tolist()\n",
    "X_train, y_train = drop_empty_list(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5888ae1b",
   "metadata": {},
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "515e6573",
   "metadata": {},
   "source": [
    "max_len = 70\n",
    "below_threshold_len(max_len, X_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a2433ddc",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val, X_test = padding_and_split(X_train, X_test, y_train, max_len)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4f53118a",
   "metadata": {},
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = lstm_model(vocab_size, embedding_dim)\n",
    "\n",
    "# 모델 검증\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'best_lstm_model_{name}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0a200ad5",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1fafaea6",
   "metadata": {},
   "source": [
    "X_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8fd5dbc5",
   "metadata": {},
   "source": [
    "y_test = np.array(test.label)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bf8403c8",
   "metadata": {},
   "source": [
    "y_test.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4a3a60db",
   "metadata": {},
   "source": [
    "# 테스트 정확도 측정\n",
    "\n",
    "loaded_model = load_model(f'best_lstm_model_{name}.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1ce4fd25",
   "metadata": {},
   "source": [
    "## Sentence Piece 결과 정리 (test acc 기준)\n",
    "- lstm model : 0.8601\n",
    "- stacked lstm model : 0.8517\n",
    "- 1d cnn model : 0.8557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1337d6",
   "metadata": {},
   "source": [
    "## 최종 형태소별 성능 정리 ( lstm model )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd2fcb",
   "metadata": {},
   "source": [
    "- hannanum : 0.8199 (빈 샘플 수 : 5513)\n",
    "- komoran : 0.8544 (빈 샘플 수 : 2278)\n",
    "- mecab : 0.8649 (빈 샘플 수 : 202)\n",
    "- okt\n",
    "    - stem = False : 0.8586 (빈 샘플 수 : 395)\n",
    "    - stem = True : 0.8613 (빈 샘플 수 : 241)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b8d41",
   "metadata": {},
   "source": [
    "- 빈 샘플 수에 비례해 성능이 좋아지는 것을 볼 수 있다\n",
    "- 이에 따라 성능 향상에 토큰을 잘 나누는 것이 매우 중요한 요소로 보인다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ed084",
   "metadata": {},
   "source": [
    "## SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdd3f30",
   "metadata": {},
   "source": [
    "- mecab의 vocab size가 21741이었으므로 이를 따라 해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0c910314",
   "metadata": {},
   "source": [
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-nsmc.train.ko.temp'\n",
    "\n",
    "vocab_size = 21741\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in corpus:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dedfdc89",
   "metadata": {},
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2105c250",
   "metadata": {},
   "source": [
    "test_data = test.document.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8c884ade",
   "metadata": {},
   "source": [
    "def sp_tokenize(s, corpus): \n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    " \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    #tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a604cd99",
   "metadata": {},
   "source": [
    "tensor, word_index, index_word = sp_tokenize(s, corpus)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1bb9a2b2",
   "metadata": {},
   "source": [
    "num_tokens = [len(tokens) for tokens in tensor]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 평균값, 최댓값, 표준편차\n",
    "print(f\"토큰 길이 평균: {np.mean(num_tokens)}\")\n",
    "print(f\"토큰 길이 최대: {np.max(num_tokens)}\")\n",
    "print(f\"토큰 길이 표준편차: {np.std(num_tokens)}\")\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(f'설정 최대 길이: {maxlen}')\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 설정값인 {maxlen}에 포함됩니다.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2b864546",
   "metadata": {},
   "source": [
    "max_len = 60\n",
    "below_threshold_len(max_len, tensor)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4965d266",
   "metadata": {},
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen=60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3a257a0f",
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "25f2c08b",
   "metadata": {},
   "source": [
    "train.label.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7cdc8dfe",
   "metadata": {},
   "source": [
    "y = train['label']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "444b0a49",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6c2ed2dc",
   "metadata": {},
   "source": [
    "name = 'sentencepiece_10000'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "95502697",
   "metadata": {},
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = lstm_model(vocab_size, embedding_dim)\n",
    "\n",
    "# 모델 검증\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'best_lstm_model_{name}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f72b4e34",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ab8a5eb4",
   "metadata": {},
   "source": [
    "def predict_x(s, corpus):\n",
    "    \n",
    "    tensor = []\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen=42)\n",
    "\n",
    "    return tensor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1ed35f25",
   "metadata": {},
   "source": [
    "X_test = predict_x(s, test.document.tolist())\n",
    "y_test = test.label"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b35c2587",
   "metadata": {},
   "source": [
    "loaded_model = load_model('best_lstm_model_sentencepiece_10000.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "57e81c57",
   "metadata": {},
   "source": [
    "## bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a9c0af2f",
   "metadata": {},
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-nsmc.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in corpus:   # 이전에 나왔던 정제했던 corpus를 활용해서 진행해야 합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={} --model_type=bpe'.format(temp_file, vocab_size)    \n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3768cc61",
   "metadata": {},
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c44b3b83",
   "metadata": {},
   "source": [
    "test_data = test.document.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "77386a1d",
   "metadata": {},
   "source": [
    "def sp_tokenize(s, corpus): \n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    " \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    #tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "dcac00d7",
   "metadata": {},
   "source": [
    "tensor, word_index, index_word = sp_tokenize(s, corpus)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "28a59622",
   "metadata": {},
   "source": [
    "num_tokens = [len(tokens) for tokens in tensor]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 평균값, 최댓값, 표준편차\n",
    "print(f\"토큰 길이 평균: {np.mean(num_tokens)}\")\n",
    "print(f\"토큰 길이 최대: {np.max(num_tokens)}\")\n",
    "print(f\"토큰 길이 표준편차: {np.std(num_tokens)}\")\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(f'설정 최대 길이: {maxlen}')\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 설정값인 {maxlen}에 포함됩니다.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d3058f67",
   "metadata": {},
   "source": [
    "max_len = 60\n",
    "below_threshold_len(max_len, tensor)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7dc09ce1",
   "metadata": {},
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='pre', maxlen=60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "749ac819",
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6328d7ca",
   "metadata": {},
   "source": [
    "train.label.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1ee22c24",
   "metadata": {},
   "source": [
    "y = train['label']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "19f58def",
   "metadata": {},
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3795a13b",
   "metadata": {},
   "source": [
    "name = 'sentencepiece_bpe'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "31b94698",
   "metadata": {},
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = lstm_model(vocab_size, embedding_dim)\n",
    "\n",
    "# 모델 검증\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint(f'best_lstm_model_{name}.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[es, mc])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "908b5a14",
   "metadata": {},
   "source": [
    "draw_graph(history)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "11abb7ed",
   "metadata": {},
   "source": [
    "X_test = predict_x(s, test.document.tolist())\n",
    "y_test = test.label"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "af46c9fc",
   "metadata": {},
   "source": [
    "loaded_model = load_model('best_lstm_model_sentencepiece_bpe.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1c5d53ba",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "73bc2fde",
   "metadata": {},
   "source": [
    "pred = loaded_model.predict(X_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ed971416",
   "metadata": {},
   "source": [
    "y_pred = np.round(pred).flatten().tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8d61a54b",
   "metadata": {},
   "source": [
    "y_true = y_test.tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b5c8cb86",
   "metadata": {},
   "source": [
    "print(classification_report(y_true, y_pred))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b6d4cc3d",
   "metadata": {},
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1aa03712",
   "metadata": {},
   "source": [
    "roc_auc_score(y_true, pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f5c8ba3c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def get_roc_curve(model_path, X_test, y_test):\n",
    "    # 모델 불러오기\n",
    "    loaded_model = load_model(model_path)\n",
    "\n",
    "    # 테스트 데이터에 대한 예측 수행\n",
    "    y_pred_prob = loaded_model.predict(X_test)  # 모델이 예측한 확률 값\n",
    "\n",
    "    # ROC 곡선 계산\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # ROC 곡선 그리기\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))\n",
    "    print(\"ROC AUC: %.4f\" % roc_auc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1aea4dd6",
   "metadata": {},
   "source": [
    "path = 'best_lstm_model_sentencepiece_bpe.h5'\n",
    "get_roc_curve(path, X_test, y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b19ad115",
   "metadata": {},
   "source": [
    "# 최종 성능 비교 및 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0afae73",
   "metadata": {},
   "source": [
    "## Sentence Piece 결과 정리 (test acc 기준)\n",
    "- lstm model : 0.8601\n",
    "- stacked lstm model : 0.8517\n",
    "- 1d cnn model : 0.8557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94edc2f8",
   "metadata": {},
   "source": [
    "## 최종 형태소별 성능 정리 ( lstm model )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369209d",
   "metadata": {},
   "source": [
    "- hannanum : 0.8199 (빈 샘플 수 : 5513)\n",
    "- komoran : 0.8544 (빈 샘플 수 : 2278)\n",
    "- mecab : 0.8649 (빈 샘플 수 : 202)\n",
    "- okt\n",
    "    - stem = False : 0.8586 (빈 샘플 수 : 395)\n",
    "    - stem = True : 0.8613 (빈 샘플 수 : 241)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df73ff",
   "metadata": {},
   "source": [
    "- 빈 샘플 수에 비례해 성능이 좋아지는 것을 볼 수 있다\n",
    "- 이에 따라 성능 향상에 토큰을 잘 나누는 것이 매우 중요한 요소로 보인다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b3f14",
   "metadata": {},
   "source": [
    "## SentencePiece vocab size, model type 변화\n",
    "- vocab_size = 21741로 늘림 : 0.8608\n",
    "- model type = bpe로 변경 : 0.8601\n",
    "\n",
    "    - 성능 향상에 큰 변화가 없었다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed5bdf",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 배운 점 \n",
    "    - 언젠가 한번 쯤은 형태소 분석기별로 성능을 비교해보고 싶었는데 이번 기회로 제대로 비교할 수 있었던 좋은 기회였다\n",
    "    - 좀 더 task specific하게 전처리를 진행해볼 수 있어 좋은 기회였다\n",
    "- 아쉬운 점 \n",
    "    - 좀 더 체계적으로 비교를 해보고 싶었는데 시간상의 이유로 제대로 비교해보지 못해서 아쉽다\n",
    "- 느낀 점\n",
    "    - task 별로 성능이 좋은 모델, 토큰화 방식이 다를 수 있다.\n",
    "- 어려웠던 점 \n",
    "    - 코드를 좀 더 재사용성있게 짜는 방법을 더 고민해봐야겠다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
