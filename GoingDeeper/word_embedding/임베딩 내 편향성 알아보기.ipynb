{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28208b25",
   "metadata": {},
   "source": [
    "# ì„ë² ë”© ë‚´ í¸í–¥ì„± ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff99cc",
   "metadata": {},
   "source": [
    "## WEAT êµ¬í˜„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c3122ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:15:55.587220Z",
     "start_time": "2024-07-04T02:15:55.585021Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3fbd089e",
   "metadata": {},
   "source": [
    "ìš°ì„  ë‘ ê°œì˜ target ë‹¨ì–´ ì…‹ X, Yì™€ ë‘ ê°œì˜ attribute ë‹¨ì–´ ì…‹ A, Bë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "ë‹¨ì–´ ì…‹ì„ ì •í•  ë•ŒëŠ” ë‘ ê°œì˜ target ì…‹ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼ í•˜ê³ , ë‘ ê°œì˜ attribute ì…‹ì˜ í¬ê¸°ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "###### targets\n",
    "- X set(ê½ƒ) : ì¥ë¯¸, íŠ¤ë¦½, ë°±í•©, ë°ì´ì§€\n",
    "- Y set(ê³¤ì¶©) : ê±°ë¯¸, ëª¨ê¸°, íŒŒë¦¬, ë©”ëšœê¸°\n",
    "\n",
    "###### attributes\n",
    "- A set(ìœ ì¾Œ) : ì‚¬ë‘, í–‰ë³µ, ì›ƒìŒ\n",
    "- B set(ë¶ˆì¾Œ) : ì¬ë‚œ, ê³ í†µ, ì¦ì˜¤\n",
    "ìœ„ ë‹¨ì–´ë“¤ì˜ ì„ë² ë”© ê²°ê³¼ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5718a60f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:17:43.177544Z",
     "start_time": "2024-07-04T02:17:43.168767Z"
    }
   },
   "source": [
    "target_X = {\n",
    "    'ì¥ë¯¸': [4.1, 1.2, -2.4, 0.5, 4.1],\n",
    "    'íŠ¤ë¦½': [3.1, 0.5, 3.6, 1.7, 5.8],\n",
    "    'ë°±í•©': [2.9, -1.3, 0.4, 1.1, 3.7],\n",
    "    'ë°ì´ì§€': [5.4, 2.5, 4.6, -1.0, 3.6]\n",
    "}\n",
    "target_Y = {\n",
    "    'ê±°ë¯¸': [-1.5, 0.2, -0.6, -4.6, -5.3],\n",
    "    'ëª¨ê¸°': [0.4, 0.7, -1.9, -4.5, -2.9],\n",
    "    'íŒŒë¦¬': [0.9, 1.4, -2.3, -3.9, -4.7],\n",
    "    'ë©”ëšœê¸°': [0.7, 0.9, -0.4, -4.1, -3.9]\n",
    "}\n",
    "attribute_A = {\n",
    "    'ì‚¬ë‘':[2.8,  4.2, 4.3,  0.3, 5.0],\n",
    "    'í–‰ë³µ':[3.8,  3. , -1.2,  4.4, 4.9],\n",
    "    'ì›ƒìŒ':[3.7, -0.3,  1.2, -2.5, 3.9]\n",
    "}\n",
    "attribute_B = {\n",
    "    'ì¬ë‚œ': [-0.2, -2.8, -4.7, -4.3, -4.7],\n",
    "    'ê³ í†µ': [-4.5, -2.1, -3.8, -3.6, -3.1],\n",
    "    'ì¦ì˜¤': [-3.6, -3.3, -3.5, -3.7, -4.4]\n",
    "}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09af01c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:17:56.892358Z",
     "start_time": "2024-07-04T02:17:56.884724Z"
    }
   },
   "source": [
    "X = np.array([v for v in target_X.values()])\n",
    "Y = np.array([v for v in target_Y.values()])\n",
    "print(X)\n",
    "print(Y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9abc2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:18:09.913007Z",
     "start_time": "2024-07-04T02:18:09.885771Z"
    }
   },
   "source": [
    "A = np.array([v for v in attribute_A.values()])\n",
    "B = np.array([v for v in attribute_B.values()])\n",
    "print(A)\n",
    "print(B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42484d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:18:21.055670Z",
     "start_time": "2024-07-04T02:18:21.042783Z"
    }
   },
   "source": [
    "def cos_sim(i, j):\n",
    "    return dot(i, j.T)/(norm(i)*norm(j))\n",
    "\n",
    "def s(w, A, B):\n",
    "    c_a = cos_sim(w, A)\n",
    "    c_b = cos_sim(w, B)\n",
    "    mean_A = np.mean(c_a, axis=-1)\n",
    "    mean_B = np.mean(c_b, axis=-1)\n",
    "    return mean_A - mean_B #, c_a, c_b\n",
    "\n",
    "print(s(target_X['ì¥ë¯¸'], A, B))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9b4afd76",
   "metadata": {},
   "source": [
    "WEAT scoreê°’ì´ ì–‘ìˆ˜ì´ë¯€ë¡œ, target_Xì— ìˆëŠ” 'ì¥ë¯¸'ë¼ëŠ” ë‹¨ì–´ëŠ” attribute_B(ë¶ˆì¾Œ)ë³´ë‹¤ attribute_A(ìœ ì¾Œ)ì™€ ë” ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. target_Yì— ìˆëŠ” 'ê±°ë¯¸'ì™€ attribute_A, attribute_Bì™€ì˜ ê´€ê³„ë„ ê³„ì‚°í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef3902b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:18:27.396087Z",
     "start_time": "2024-07-04T02:18:27.392481Z"
    }
   },
   "source": [
    "print(s(target_Y['ê±°ë¯¸'], A, B))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2aed3e1d",
   "metadata": {},
   "source": [
    "ìœ„ì™€ ë°˜ëŒ€ë¡œ WEAT scoreê°€ ìŒìˆ˜ê°€ ë‚˜ì™”ìœ¼ë¯€ë¡œ, 'ê±°ë¯¸'ëŠ” attribute_Bì™€ ë” ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¼ target_Xì™€ attribute_A, attribute_B ì‚¬ì˜ì˜ í‰ê· ê°’, ê·¸ë¦¬ê³  target_Yì™€ attribute_A, attribute_B ì‚¬ì˜ì˜ í‰ê· ê°’ì€ ì–´ë–»ê²Œ ë ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2059d5c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:18:35.287341Z",
     "start_time": "2024-07-04T02:18:35.279736Z"
    }
   },
   "source": [
    "print(s(X, A, B))\n",
    "print(round(np.mean(s(X, A, B)), 3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "34703c41",
   "metadata": {},
   "source": [
    "target_Xì™€ attribute_A, attribute_B ì‚¬ì´ì˜ í‰ê· ê°’ì€ 0.397ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd166b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:19:03.633813Z",
     "start_time": "2024-07-04T02:19:03.629915Z"
    }
   },
   "source": [
    "print(s(Y, A, B))\n",
    "print(round(np.mean(s(Y, A, B)), 3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a138f222",
   "metadata": {},
   "source": [
    "target_Yì™€ attribute_A, attribute_B ì‚¬ì´ì˜ í‰ê· ê°’ì€ -0.33ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¼ ì´ë²ˆì—ëŠ” WEAT scoreì˜ ìˆ˜ì‹ ì „ì²´ë¥¼ ì½”ë“œë¡œ ë‚˜íƒ€ë‚´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c59b21a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:20:10.225913Z",
     "start_time": "2024-07-04T02:20:10.203494Z"
    }
   },
   "source": [
    "def weat_score(X, Y, A, B):\n",
    "    \n",
    "    s_X = s(X, A, B)\n",
    "    s_Y = s(Y, A, B)\n",
    "\n",
    "    mean_X = np.mean(s_X)\n",
    "    mean_Y = np.mean(s_Y)\n",
    "    \n",
    "    std_dev = np.std(np.concatenate([s_X, s_Y], axis=0))\n",
    "    \n",
    "    return  (mean_X-mean_Y)/std_dev\n",
    "\n",
    "print(round(weat_score(X, Y, A, B), 3))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d3a91f23",
   "metadata": {},
   "source": [
    "WEAT scoreê°€ ë§¤ìš° ë†’ê²Œ ë‚˜ì˜¨ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, ê½ƒì€ ìœ ì¾Œí•œ ë‹¨ì–´ì™€ ìƒëŒ€ì ìœ¼ë¡œ ê°€ê¹ê³ , ê³¤ì¶©ì€ ë¶ˆì¾Œí•œ ë‹¨ì–´ì™€ ê°€ê¹ë‹¤ëŠ” ê²ƒì„ ìˆ˜ì¹˜ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•´ë³¼ê¹Œìš”? PCAë¥¼ í†µí•´ 5ì°¨ì›ì´ì—ˆë˜ ë²¡í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ì¤„ì—¬ ê·¸ë¦¼ì„ ê·¸ë ¤ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4b391c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:20:26.422964Z",
     "start_time": "2024-07-04T02:20:25.949163Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pc_A = pca.fit_transform(A)\n",
    "pc_B = pca.fit_transform(B)\n",
    "pc_X = pca.fit_transform(X)\n",
    "pc_Y = pca.fit_transform(Y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pc_A[:,0],pc_A[:,1], c='blue', label='A')\n",
    "ax.scatter(pc_B[:,0],pc_B[:,1], c='red', label='B')\n",
    "ax.scatter(pc_X[:,0],pc_X[:,1], c='skyblue', label='X')\n",
    "ax.scatter(pc_Y[:,0],pc_Y[:,1], c='pink', label='Y')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7af3fb9b",
   "metadata": {},
   "source": [
    "## ì‚¬ì „í•™ìŠµëœ Word Embeddingì— WEAT ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e93bb97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T02:18:36.098268Z",
     "start_time": "2024-07-04T02:18:36.096437Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "data_dir = '~/aiffel/weat' \n",
    "model_dir = os.path.join(data_dir, 'GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 50ë§Œê°œì˜ ë‹¨ì–´ë§Œ í™œìš©í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë‹¤ë©´ limit íŒŒë¼ë¯¸í„°ê°’ì„ ìƒëµí•˜ì—¬ 300ë§Œê°œë¥¼ ëª¨ë‘ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cd93b0",
   "metadata": {},
   "source": [
    "w2v"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b9daebc0",
   "metadata": {},
   "source": [
    "w2vì— ìˆëŠ” ë‹¨ì–´ ê°œìˆ˜ì™€ ë²¡í„° í¬ê¸°ë¥¼ ì‚´í´ë³¼ê¹Œìš”?\n",
    "\n",
    "ğŸ’¡ ì°¸ê³ \n",
    "2021ë…„ 3ì›”, Gensimì´ 4.0 ìœ¼ë¡œ ë²„ì „ì—…ë˜ë©´ì„œ KeyedVectorsì— vocab dictê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ë§í¬ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "Migrating from Gensim 3.x to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cf31df",
   "metadata": {},
   "source": [
    "# print(len(w2v.vocab))   # Gensim 3.X ë²„ì „ê¹Œì§€ëŠ” w2v.vocabì„ ì§ì ‘ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "print(len(w2v.index_to_key))   # Gensim 4.0ë¶€í„°ëŠ” index_to_keyë¥¼ í™œìš©í•´ vocab sizeë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "print(len(w2v['I']))                    # í˜¹ì€ ë‹¨ì–´ë¥¼ keyë¡œ ì§ì ‘ vectorë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "print(w2v.vectors.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0798dd4",
   "metadata": {},
   "source": [
    "w2v['happy']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65718d41",
   "metadata": {},
   "source": [
    "w2v.most_similar(positive=['happy'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48020a8c",
   "metadata": {},
   "source": [
    "w2v.most_similar(positive=['family'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23673a83",
   "metadata": {},
   "source": [
    "w2v.most_similar(positive=['school'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a58b21af",
   "metadata": {},
   "source": [
    "target_X = ['science', 'technology', 'physics', 'chemistry', 'Einstein', 'NASA', 'experiment', 'astronomy']\n",
    "target_Y = ['poetry', 'art', 'Shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "attribute_A = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_B = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6439e997",
   "metadata": {},
   "source": [
    "ê³¼í•™ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ê°€ ë‚¨ì„±ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ì™€ ê°€ê¹ê³ , ì˜ˆìˆ ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ê°€ ì—¬ì„±ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ì™€ ê°€ê¹ê²Œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì‚¬ëŒì˜ í¸í–¥ì„±ì„ ì‹¤í—˜í•˜ëŠ” IATì—ì„œë„ ì´ì™€ ê°™ê²Œ ë‚˜íƒ€ë‚¬ì—ˆì£ ? ë§ì€ ì‚¬ëŒì´ ê°€ì§„ í¸í–¥ì´ ì„ë² ë”© ëª¨ë¸ì— ë°˜ì˜ë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ë‹¤ë¥¸ ì…‹ì„ êµ¬ì„±í•´ë³¼ê¹Œìš”? target_XëŠ” ì¸ìŠ¤í„´íŠ¸ ì‹í’ˆë“¤ë¡œ ë‹¨ì–´ë¥¼ êµ¬ì„±í•˜ì˜€ê³  target_YëŠ” ê·¸ ë°˜ëŒ€ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤. attribute_AëŠ” ì¸ìŠ¤í„´íŠ¸ë¥¼ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ë“¤ë¡œ, attributes_BëŠ” ê·¸ ë°˜ëŒ€ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë‹¨ì–´ ì…‹ë“¤ì„ ë³´ë©´ target_XëŠ” attribute_Aì™€ attribute_B ì¤‘ ì–´ë–¤ ê²ƒê³¼ ê°€ê¹ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?\n",
    "ë³´í†µ target_Xì™€ attribute_Aê°€ ê°€ê¹ê³ , traget_YëŠ” attribute_Bì™€ ê°€ê¹ë‹¤ê³  ëŒ€ë‹µí•  ê²ƒì…ë‹ˆë‹¤.\n",
    "ì„ë² ë”© ëª¨ë¸ë„ ê·¸ë ‡ê²Œ ìƒê°í• ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ad8ffdd",
   "metadata": {},
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['junk', 'canned', 'convenience', 'frozen', 'fast']\n",
    "attribute_B = ['health', 'beneficial', 'good', 'nourishing', 'nutritious']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9275996a",
   "metadata": {},
   "source": [
    "ëª¨ë¸ë„ ìš°ë¦¬ì˜ ì˜ˆìƒê³¼ ë§ëŠ” ë°©í–¥ìœ¼ë¡œ ìƒë‹¹íˆ ë†’ì€ ìˆ˜ì¹˜ë¥¼ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì¸ìŠ¤í„´íŠ¸ ì‹í’ˆì˜ ì˜ˆì‹œì™€ ì¸ìŠ¤í„´íŠ¸ë¥¼ ì˜ë¯¸í•˜ëŠ” ë‹¨ì–´ê°€ ê°€ê¹Œìš´ ê²ƒì€ ë‹¹ì—°í•©ë‹ˆë‹¤. ì´ ê²½ìš° ëª¨ë¸ì´ í¸í–¥ë˜ì–´ìˆë‹¤ê¸°ë³´ë‹¤ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì˜ íŒŒì•…í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë™ì¼í•œ target ì…‹ì— ë‹¤ë¥¸ attribute ì…‹ì„ ë§Œë“¤ë³¼ê¹Œìš”? attribute_Aì—ëŠ” ì±…ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ë¡œ êµ¬ì„±í•˜ê³ , attribute_BëŠ” ë‰´ìŠ¤ì™€ ê´€ë ¨ëœ ë‹¨ì–´ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ì–´ë–¤ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5887ccd",
   "metadata": {},
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['book', 'essay', 'dictionary', 'magazine', 'novel']\n",
    "attribute_B = ['news', 'report', 'statement', 'broadcast', 'word']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ba2e3fae",
   "metadata": {},
   "source": [
    "0ì— êµ‰ì¥íˆ ê°€ê¹Œìš´ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì¦‰, ì„ë² ë”© ëª¨ë¸ì´ íŒë‹¨í•˜ê¸°ì— ì–´ëŠ ê²ƒë¼ë¦¬ ê°€ê¹ë‹¤ê³  ë§í•  ìˆ˜ ì—†ëŠ” ê²ƒì´ì§€ìš”.\n",
    "\n",
    "ì—¬ëŸ¬ë¶„ì´ target, attribute ì…‹ì„ ë§Œë“¤ì–´ì„œ WEAT scoreë¥¼ êµ¬í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "307eac51",
   "metadata": {},
   "source": [
    "target_X = ['student']\n",
    "target_Y = ['teacher']\n",
    "attribute_A = ['new']\n",
    "attribute_B = ['old']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba903bf1",
   "metadata": {},
   "source": [
    "#ë©”ëª¨ë¦¬ë¥¼ ë‹¤ì‹œ ë¹„ì›Œì¤ì‹œë‹¤.\n",
    "del w2v\n",
    "print(\"ì‚­ì œ ì™„ë£Œ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "69a1f69a",
   "metadata": {},
   "source": [
    "## ì§ì ‘ ë§Œë“œëŠ” Word Embeddingì— WEAT ì ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f56db6",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆê¹Œì§€ëŠ” ì œì‹œëœ ëª¨ë¸ê³¼ ë‹¨ì–´ë“¤ë¡œ WEAT scoreë¥¼ êµ¬í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ì œ ì£¼ì–´ì§„ ë°ì´í„°ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ìˆ˜í–‰í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì´ìš©í•˜ì—¬ í’ˆì‚¬ê°€ ëª…ì‚¬ì¸ ê²½ìš°, í•´ë‹¹ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ê¸°\n",
    "2. ì¶”ì¶œëœ ê²°ê³¼ë¡œ embedding model ë§Œë“¤ê¸°\n",
    "3. TF/IDFë¡œ í•´ë‹¹ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ í‘œí˜„í•˜ëŠ” ë‹¨ì–´ ì…‹ ë§Œë“¤ê¸°\n",
    "4. embedding modelê³¼ ë‹¨ì–´ ì…‹ìœ¼ë¡œ WEAT score êµ¬í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6fa4c7",
   "metadata": {},
   "source": [
    "## 1. í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì´ìš©í•˜ì—¬ í’ˆì‚¬ê°€ ëª…ì‚¬ì¸ ê²½ìš° í•´ë‹¹ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ê¸°\n",
    "synopsis.txt(ëŒ€ëµ 17MB)ì—ëŠ” 2001ë…„ë¶€í„° 2019ë…„ 8ì›”ê¹Œì§€ ì œì‘ëœ ì˜í™”ë“¤ì˜ ì‹œë†‰ì‹œìŠ¤ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤. (ê°œë´‰ëœ ì˜í™” ì¤‘ ì¼ë¶€ë§Œ í¬í•¨ë˜ì–´ìˆìŠµë‹ˆë‹¤. ë” ë§ì€ ì˜í™” ì •ë³´ë¥¼ ì›í•˜ì‹œë©´ KOBISì—ì„œ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.) synopsis.txtì˜ ì¼ë¶€ë¥¼ ì½ì–´ë³¼ê¹Œìš”?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T03:38:19.725958Z",
     "start_time": "2024-07-04T03:38:19.723371Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "id": "278f8e38f7c7e6d0",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ed98f6f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T03:38:59.919226Z",
     "start_time": "2024-07-04T03:38:59.912525Z"
    }
   },
   "source": [
    "with open('./synopsis/synopsis.txt', 'r') as file:\n",
    "    for i in range(20):\n",
    "        print(file.readline(), end='')"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "efdf3ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T03:55:13.559517Z",
     "start_time": "2024-07-04T03:55:13.331717Z"
    }
   },
   "source": [
    "# ì•½ 15ë¶„ì •ë„ ê±¸ë¦½ë‹ˆë‹¤.\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "tokenized = []\n",
    "with open(os.getenv('HOME')+'/aiffel/weat/synopsis.txt', 'r') as file:\n",
    "    while True:\n",
    "        line = file.readline()\n",
    "        if not line: break\n",
    "        words = okt.pos(line, stem=True, norm=True)\n",
    "        res = []\n",
    "        for w in words:\n",
    "            if w[1] in [\"Noun\"]:      # \"Adjective\", \"Verb\" ë“±ì„ í¬í•¨í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "                res.append(w[0])    # ëª…ì‚¬ì¼ ë•Œë§Œ tokenized ì— ì €ì¥í•˜ê²Œ ë©ë‹ˆë‹¤. \n",
    "        tokenized.append(res)\n",
    "\n",
    "print(\"ìŠ~\")"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a1da7a5",
   "metadata": {},
   "source": [
    "print(len(tokenized))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f994636",
   "metadata": {},
   "source": [
    "## 2. ì¶”ì¶œëœ ê²°ê³¼ë¡œ embedding model ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bcf07cd",
   "metadata": {},
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# tokenizedì— ë‹´ê¸´ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ë‚˜ë§Œì˜ Word2Vecì„ ìƒì„±í•©ë‹ˆë‹¤. (Gensim 4.0 ê¸°ì¤€)\n",
    "model = Word2Vec(tokenized, vector_size=100, window=5, min_count=3, sg=0)  \n",
    "model.wv.most_similar(positive=['ì˜í™”'])\n",
    "\n",
    "# Gensim 3.X ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "# model = Word2Vec(tokenized, size=100, window=5, min_count=3, sg=0)  \n",
    "# model.most_similar(positive=['ì˜í™”'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7dcc25d",
   "metadata": {},
   "source": [
    "model.wv.most_similar(positive=['ì‚¬ë‘'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23301fef",
   "metadata": {},
   "source": [
    "model.wv.most_similar(positive=['ì—°ê·¹'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6a87b13d",
   "metadata": {},
   "source": [
    "## 3. TF-IDFë¡œ í•´ë‹¹ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ í‘œí˜„í•˜ëŠ” ë‹¨ì–´ ì…‹ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b238b6b6",
   "metadata": {},
   "source": [
    "WEAT scoreë¥¼ êµ¬í•  ë•Œ ë‹¨ì–´ ì…‹ì„ ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. targets_X, targets_Y, attribute_A, attribute_Bë¥¼ ë§Œë“¤ì–´ì£¼ì—ˆë˜ ê²ƒì´ ê¸°ì–µë‚˜ì‹œì£ ? ì´ì œ ë‘ ì¶•ì„ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì¡ê³ , í•´ë‹¹ ì¶•ì˜ ì–´ë–¤ í•­ëª©ì„ ì‚¬ìš©í• ì§€ ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” ë‘ ì¶•ì„ ì˜í™” ì¥ë¥´, ì˜í™” êµ¬ë¶„ ì •ë³´ë¥¼ ì´ìš©í•˜ê² ìŠµë‹ˆë‹¤. (ì˜í™” êµ¬ë¶„ ì •ë³´ë€ ì¼ë°˜ì˜í™”, ì˜ˆìˆ ì˜í™”, ë…ë¦½ì˜í™”ë¡œ êµ¬ë¶„ëœ ì •ë³´ì…ë‹ˆë‹¤. KOBISì—ì„œ ì œê³µí•œ ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•˜ì˜€ìŠµë‹ˆë‹¤.)\n",
    "\n",
    "#### ì˜í™” êµ¬ë¶„\n",
    "- synopsis_art.txt : ì˜ˆìˆ ì˜í™”\n",
    "- synopsis_gen.txt : ì¼ë°˜ì˜í™”(ìƒì—…ì˜í™”)\n",
    "- ê·¸ ì™¸ëŠ” ë…ë¦½ì˜í™” ë“±ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### ì¥ë¥´ êµ¬ë¶„\n",
    "- synopsis_SF.txt: SF\n",
    "- synopsis_ê°€ì¡±.txt: ê°€ì¡±\n",
    "- synopsis_ê³µì—°.txt: ê³µì—°\n",
    "- synopsis_ê³µí¬(í˜¸ëŸ¬).txt: ê³µí¬(í˜¸ëŸ¬)\n",
    "- synopsis_ê¸°íƒ€.txt: ê¸°íƒ€\n",
    "- synopsis_ë‹¤íë©˜í„°ë¦¬.txt: ë‹¤íë©˜í„°ë¦¬\n",
    "- synopsis_ë“œë¼ë§ˆ.txt: ë“œë¼ë§ˆ\n",
    "- synopsis_ë©œë¡œë¡œë§¨ìŠ¤.txt: ë©œë¡œë¡œë§¨ìŠ¤\n",
    "- synopsis_ë®¤ì§€ì»¬.txt: ë®¤ì§€ì»¬\n",
    "- synopsis_ë¯¸ìŠ¤í„°ë¦¬.txt: ë¯¸ìŠ¤í„°ë¦¬\n",
    "- synopsis_ë²”ì£„.txt: ë²”ì£„\n",
    "- synopsis_ì‚¬ê·¹.txt: ì‚¬ê·¹\n",
    "- synopsis_ì„œë¶€ê·¹(ì›¨ìŠ¤í„´).txt: ì„œë¶€ê·¹(ì›¨ìŠ¤í„´)\n",
    "- synopsis_ì„±ì¸ë¬¼(ì—ë¡œ).txt: ì„±ì¸ë¬¼(ì—ë¡œ)\n",
    "- synopsis_ìŠ¤ë¦´ëŸ¬.txt: ìŠ¤ë¦´ëŸ¬\n",
    "- synopsis_ì• ë‹ˆë©”ì´ì…˜.txt: ì• ë‹ˆë©”ì´ì…˜\n",
    "- synopsis_ì•¡ì…˜.txt: ì•¡ì…˜\n",
    "- synopsis_ì–´ë“œë²¤ì²˜.txt: ì–´ë“œë²¤ì²˜\n",
    "- synopsis_ì „ìŸ.txt: ì „ìŸ\n",
    "- synopsis_ì½”ë¯¸ë””.txt: ì½”ë¯¸ë””\n",
    "- synopsis_íŒíƒ€ì§€.txt: íŒíƒ€ì§€\n",
    "\n",
    "ì´ë²ˆì—ëŠ” ì˜ˆìˆ ì˜í™”ì™€ ì¼ë°˜ì˜í™”(ìƒì—…ì˜í™”)ë¼ëŠ” ì˜í™”êµ¬ë¶„ì„ targetìœ¼ë¡œ ì‚¼ê³ , ë“œë¼ë§ˆ ì¥ë¥´ì™€ ì•¡ì…˜ ì¥ë¥´ë¼ëŠ” ì¥ë¥´êµ¬ë¶„ì„ attributeë¡œ ì‚¼ì•„ WEAT scoreë¥¼ ê³„ì‚°í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì¦‰ ë“œë¼ë§ˆ ì¥ë¥´ì—ëŠ” ì˜ˆìˆ ì˜í™”ì  ì„±ê²©ì´ ê°•í•˜ê³ , ì•¡ì…˜ ì¥ë¥´ì—ëŠ” ì¼ë°˜(ìƒì—…)ì˜í™”ì  ì„±ê²©ì´ ê°•í•  ê²ƒì´ë¼ëŠ” í¸í–¥ì„±ì´ ì›Œë“œ ì„ë² ë”© ìƒì— ì–¼ë§ˆë‚˜ ë‚˜íƒ€ë‚˜ê³  ìˆëŠ”ì§€ë¥¼ ì¸¡ì •í•´ ë³´ê² ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "'synopsis_art.txt', 'synopsis_gen.txt' ë‘ íŒŒì¼ì„ ì½ê³ , ìœ„ì—ì„œ í–ˆë˜ ê²ƒê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ëª…ì‚¬ì— ëŒ€í•´ì„œë§Œ ì¶”ì¶œí•˜ì—¬ art, gen ë³€ìˆ˜ì— í• ë‹¹í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570b4b9",
   "metadata": {},
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "art_txt = 'synopsis_art.txt'\n",
    "gen_txt = 'synopsis_gen.txt'\n",
    "\n",
    "def read_token(file_name):\n",
    "    okt = Okt()\n",
    "    result = []\n",
    "    with open(os.getenv('HOME')+'/aiffel/weat/'+file_name, 'r') as fread: \n",
    "        print(file_name, 'íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤.')\n",
    "        while True:\n",
    "            line = fread.readline() \n",
    "            if not line: break \n",
    "            tokenlist = okt.pos(line, stem=True, norm=True) \n",
    "            for word in tokenlist:\n",
    "                if word[1] in [\"Noun\"]:#, \"Adjective\", \"Verb\"]:\n",
    "                    result.append((word[0])) \n",
    "    return ' '.join(result)\n",
    "\n",
    "print(\"ìŠ~\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f6ca68",
   "metadata": {},
   "source": [
    "# 2ê°œì˜ íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ”ë° 10ë¶„ ê°€ëŸ‰ ê±¸ë¦½ë‹ˆë‹¤. \n",
    "art = read_token(art_txt)\n",
    "gen = read_token(gen_txt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d394e23a",
   "metadata": {},
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform([art, gen])\n",
    "\n",
    "print(X.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ac93a",
   "metadata": {},
   "source": [
    "print(vectorizer.vocabulary_['ì˜í™”'])\n",
    "print(vectorizer.get_feature_names()[23976])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9d146",
   "metadata": {},
   "source": [
    "m1 = X[0].tocoo()   # artë¥¼ TF-IDFë¡œ í‘œí˜„í•œ sparse matrixë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. \n",
    "m2 = X[1].tocoo()   # genì„ TF-IDFë¡œ í‘œí˜„í•œ sparse matrixë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. \n",
    "\n",
    "w1 = [[i, j] for i, j in zip(m1.col, m1.data)]\n",
    "w2 = [[i, j] for i, j in zip(m2.col, m2.data)]\n",
    "\n",
    "w1.sort(key=lambda x: x[1], reverse=True)   #artë¥¼ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´ë“¤ì„ TF-IDFê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. \n",
    "w2.sort(key=lambda x: x[1], reverse=True)   #genì„ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´ë“¤ì„ TF-IDFê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤. \n",
    "\n",
    "print('ì˜ˆìˆ ì˜í™”ë¥¼ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë“¤:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w1[i][0]], end=', ')\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print('ì¼ë°˜ì˜í™”ë¥¼ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë“¤:')\n",
    "for i in range(100):\n",
    "    print(vectorizer.get_feature_names()[w2[i][0]], end=', ')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a869c590",
   "metadata": {},
   "source": [
    "ì–´ë–¤ê°€ìš”? ë‘ ê°œë…ì„ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë¥¼ TF-IDFê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì¶”ì¶œí•˜ê³  ì‹¶ì—ˆëŠ”ë°, ì–‘ìª½ì— ì¤‘ë³µëœ ë‹¨ì–´ê°€ ë„ˆë¬´ ë§ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‘ ê°œë…ì¶•ì´ ëŒ€ì¡°ë˜ë„ë¡ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ ì…‹ì„ ë§Œë“¤ê³  ì‹¶ê¸° ë•Œë¬¸ì— ë‹¨ì–´ê°€ ì„œë¡œ ì¤‘ë³µë˜ì§€ ì•Šê²Œ ë‹¨ì–´ì…‹ì„ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤. ìš°ì„  ìƒìœ„ 100ê°œì˜ ë‹¨ì–´ë“¤ ì¤‘ ì¤‘ë³µë˜ëŠ” ë‹¨ì–´ë¥¼ ì œì™¸í•˜ê³  ìƒìœ„ n(=15)ê°œì˜ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5fb1d",
   "metadata": {},
   "source": [
    "n = 15\n",
    "w1_, w2_ = [], []\n",
    "for i in range(100):\n",
    "    w1_.append(vectorizer.get_feature_names()[w1[i][0]])\n",
    "    w2_.append(vectorizer.get_feature_names()[w2[i][0]])\n",
    "\n",
    "# w1ì—ë§Œ ìˆê³  w2ì—ëŠ” ì—†ëŠ”, ì˜ˆìˆ ì˜í™”ë¥¼ ì˜ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë¥¼ 15ê°œ ì¶”ì¶œí•œë‹¤.\n",
    "target_art, target_gen = [], []\n",
    "for i in range(100):\n",
    "    if (w1_[i] not in w2_) and (w1_[i] in model.wv): target_art.append(w1_[i])\n",
    "    if len(target_art) == n: break \n",
    "\n",
    "# w2ì—ë§Œ ìˆê³  w1ì—ëŠ” ì—†ëŠ”, ì¼ë°˜ì˜í™”ë¥¼ ì˜ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë¥¼ 15ê°œ ì¶”ì¶œí•œë‹¤.\n",
    "for i in range(100):\n",
    "    if (w2_[i] not in w1_) and (w2_[i] in model.wv): target_gen.append(w2_[i])\n",
    "    if len(target_gen) == n: break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a60812",
   "metadata": {},
   "source": [
    "print(target_art)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f38acf",
   "metadata": {},
   "source": [
    "print(target_gen)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "39a2a293",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” ì¥ë¥´ë³„ ëŒ€í‘œ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•´ ë´…ì‹œë‹¤. ì´ë²ˆì—ëŠ” ë“œë¼ë§ˆ ì¥ë¥´ì™€ ì•¡ì…˜ ì¥ë¥´ë¥¼ ë‹¤ë£¨ì–´ ë³´ë ¤ê³  í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë“œë¼ë§ˆì™€ ì•¡ì…˜ ë‹¨ 2ê°œì˜ ì¥ë¥´ë§Œ ê³ ë ¤í•˜ê¸°ë³´ë‹¤ëŠ” ì—¬ëŸ¬ ì¥ë¥´ì˜ ì½”í¼ìŠ¤ë¥¼ ë‘ë£¨ ê³ ë ¤í•˜ëŠ” ê²ƒì´ íŠ¹ì • ì¥ë¥´ë¥¼ ëŒ€í‘œí•˜ëŠ” ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ë° ë” ìœ ë¦¬í•  ê²ƒì…ë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ì£¼ìš” ì¥ë¥´ 5ê°œë§Œ ê³ ë ¤í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a9f76",
   "metadata": {},
   "source": [
    "genre_txt = ['synopsis_drama.txt', 'synopsis_romance.txt', 'synopsis_action.txt', 'synopsis_comedy.txt', 'synopsis_war.txt', 'synopsis_horror.txt']\n",
    "genre_name = ['ë“œë¼ë§ˆ', 'ë©œë¡œë¡œë§¨ìŠ¤', 'ì•¡ì…˜', 'ì½”ë¯¸ë””', 'ì „ìŸ', 'ê³µí¬(í˜¸ëŸ¬)']\n",
    "\n",
    "print(\"ìŠ~\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e458fc9",
   "metadata": {},
   "source": [
    "# ì•½ 10ë¶„ì •ë„ ê±¸ë¦½ë‹ˆë‹¤.\n",
    "genre = []\n",
    "for file_name in genre_txt:\n",
    "    genre.append(read_token(file_name))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f1536",
   "metadata": {},
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(genre)\n",
    "\n",
    "print(X.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6bacd",
   "metadata": {},
   "source": [
    "m = [X[i].tocoo() for i in range(X.shape[0])]\n",
    "\n",
    "w = [[[i, j] for i, j in zip(mm.col, mm.data)] for mm in m]\n",
    "\n",
    "for i in range(len(w)):\n",
    "    w[i].sort(key=lambda x: x[1], reverse=True)\n",
    "attributes = []\n",
    "for i in range(len(w)):\n",
    "    print(genre_name[i], end=': ')\n",
    "    attr = []\n",
    "    j = 0\n",
    "    while (len(attr) < 15):\n",
    "        if vectorizer.get_feature_names()[w[i][j][0]] in model.wv:\n",
    "            attr.append(vectorizer.get_feature_names()[w[i][j][0]])\n",
    "            print(vectorizer.get_feature_names()[w[i][j][0]], end=', ')\n",
    "        j += 1\n",
    "    attributes.append(attr)\n",
    "    print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8fd7537a",
   "metadata": {},
   "source": [
    "## 4. embedding modelê³¼ ë‹¨ì–´ ì…‹ìœ¼ë¡œ WEAT score êµ¬í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66c693",
   "metadata": {},
   "source": [
    "ì´ì œ WEAT_scoreë¥¼ êµ¬í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "traget_XëŠ” art, target_YëŠ” gen, attribute_AëŠ” 'ë“œë¼ë§ˆ', attribute_BëŠ” 'ì•¡ì…˜' ê³¼ ê°™ì´ ì •í•´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "target_X ëŠ” art, target_Y ëŠ” genìœ¼ë¡œ ê³ ì •í•˜ê³  attribute_A, attribute_Bë¥¼ ë°”ê¿”ê°€ë©´ì„œ êµ¬í•´ë´…ì‹œë‹¤. êµ¬í•œ ê²°ê³¼ë¥¼ 21x21 ë§¤íŠ¸ë¦­ìŠ¤ í˜•íƒœë¡œ í‘œí˜„í•´ì„œ matrix ë¼ëŠ” ë³€ìˆ˜ì— ë‹´ì•„ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abd4ea",
   "metadata": {},
   "source": [
    "matrix = [[0 for _ in range(len(genre_name))] for _ in range(len(genre_name))]\n",
    "print(\"ìŠ~\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d0b4a",
   "metadata": {},
   "source": [
    "X = np.array([model.wv[word] for word in target_art])\n",
    "Y = np.array([model.wv[word] for word in target_gen])\n",
    "\n",
    "for i in range(len(genre_name)-1):\n",
    "    for j in range(i+1, len(genre_name)):\n",
    "        A = np.array([model.wv[word] for word in attributes[i]])\n",
    "        B = np.array([model.wv[word] for word in attributes[j]])\n",
    "        matrix[i][j] = weat_score(X, Y, A, B)\n",
    "\n",
    "print(\"ìŠ~\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "dafdd5c4",
   "metadata": {},
   "source": [
    "matrixë¥¼ ì±„ì›Œë³´ì•˜ìŠµë‹ˆë‹¤. WEAT score ê°’ì„ ë³´ê³ , ê³¼ì—° ìš°ë¦¬ì˜ ì§ê´€ê³¼ ë¹„ìŠ·í•œì§€ ì‚´í´ë³¼ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebabc927",
   "metadata": {},
   "source": [
    "for i in range(len(genre_name)-1):\n",
    "    for j in range(i+1, len(genre_name)):\n",
    "        print(genre_name[i], genre_name[j],matrix[i][j])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2d3596ba",
   "metadata": {},
   "source": [
    "WEAT scoreê°€ 0.8 ì´ìƒ, -0.8 ì´í•˜ì˜ ê²½ìš°ë§Œ í•´ì„í•´ ë³´ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆìˆ ì˜í™”ì™€ ì¼ë°˜ì˜í™”, ê·¸ë¦¬ê³  ë“œë¼ë§ˆì™€ ë©œë¡œë¡œë§¨ìŠ¤ì˜ WEAT scoreì˜ ì˜ë¯¸ë¥¼ í•´ì„í•´ë³´ë©´ ì˜ˆìˆ ì˜í™”ëŠ” ë©œë¡œë¡œë§¨ìŠ¤, ì¼ë°˜ì˜í™”ëŠ” ë“œë¼ë§ˆì™€ ê°€ê¹ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¶€í˜¸ê°€ ë§ˆì´ë„ˆìŠ¤ì´ë¯€ë¡œ ì‚¬ëŒì˜ í¸í–¥ê³¼ ë°˜ëŒ€ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì˜ˆìˆ ì˜í™”ì™€ ì¼ë°˜ì˜í™”, ê·¸ë¦¬ê³  ë©œë¡œë¡œë§¨ìŠ¤ì™€ ì½”ë¯¸ë””ì˜ WEAT scoreì˜ ì˜ë¯¸ë¥¼ í•´ì„í•´ë³´ë©´ ì˜ˆìˆ  ì˜í™”ëŠ” ë©œë¡œë¡œë§¨ìŠ¤ì™€ ê°€ê¹ê³ , ì½”ë””ë¯¸ëŠ” ì¼ë°˜ ì˜í™”ì™€ ê°€ê¹ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì˜ˆìˆ ì˜í™”ì™€ ì¼ë°˜ì˜í™”, ê·¸ë¦¬ê³  ë©œë¡œë¡œë§¨ìŠ¤ì™€ ì „ìŸì˜ WEAT scoreì˜ ì˜ë¯¸ë¥¼ í•´ì„í•´ë³´ë©´ ì˜ˆìˆ  ì˜í™”ëŠ” ë©œë¡œë¡œë§¨ìŠ¤ì™€ ê°€ê¹ê³ , ì „ìŸì€ ì¼ë°˜ ì˜í™”ì™€ ê°€ê¹ë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d1093",
   "metadata": {},
   "source": [
    "import numpy as np; \n",
    "import seaborn as sns; \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# í•œê¸€ ì§€ì› í°íŠ¸\n",
    "sns.set(font='NanumGothic')\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ \n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "ax = sns.heatmap(matrix, xticklabels=genre_name, yticklabels=genre_name, annot=True,  cmap='RdYlGn_r')\n",
    "ax"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "077126a1",
   "metadata": {},
   "source": [
    "ì§€ê¸ˆê¹Œì§€ word embedding modelì— ìˆëŠ” í¸í–¥ì„±ì„ í™•ì¸í•´ë³´ê¸° ìœ„í•´ WEAT scoreë¥¼ ì‹œë„í•´ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ í•™ìŠµì„ í†µí•´ ì—¬ëŸ¬ë¶„ì´ ê°€ì§„ ë°ì´í„°ë¡œ word embedding modelì„ ë§Œë“¤ ìˆ˜ ìˆê³ , ì´ ëª¨ë¸ì´ íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•´ í¸í–¥ì´ ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ë³¼ ìˆ˜ ìˆê²Œ ë˜ì—ˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8303fb",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
