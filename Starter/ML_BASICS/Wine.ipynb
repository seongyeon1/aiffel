{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6a9579",
   "metadata": {},
   "source": [
    "## load_wine : 와인을 분류해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326fd24",
   "metadata": {},
   "source": [
    "## 1. 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc84243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36b96c",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비\n",
    "- `load_wine` 메서드를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17023547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "# sklearn 라이브러리의 datasets 패키지에서 load_wine 함수를 임포트함\n",
    "\n",
    "wine = load_wine()\n",
    "# load_wine 함수는 wine 데이터셋을 로드하는 함수\n",
    "# 로드된 wine 데이터셋을 wine 라는 변수에 저장\n",
    "\n",
    "print(dir(wine))\n",
    "# dir()는 객체가 어떤 변수와 메서드를 가지고 있는지 나열함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15705df9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys() # wine 데이터셋에 담긴 정보 종류 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657e618",
   "metadata": {},
   "source": [
    "## 3. 데이터 이해하기\n",
    "지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
    "- Feature Data 지정하기\n",
    "- Label Data 지정하기\n",
    "- Target Names 출력해 보기\n",
    "- 데이터 Describe 해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9a071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "\n",
    "print(wine_data.shape) \n",
    "# shape는 배열의 형상정보를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4d6238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "       1.065e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[0]\n",
    "# 150개의 데이터 중 첫 번째 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2c635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_label = wine.target\n",
    "\n",
    "print(wine_label.shape)\n",
    "wine_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89499e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17742d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wine.DESCR)\n",
    "# keys에서 확인한 정보 중 DESCR을 변수에 따로 저장하지 않고 호출\n",
    "# 데이터셋 설명서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69705e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a81b7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de47dc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wine_data)\n",
    "# iris_data의 데이터 타입은 numpy의 ndarray인 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f86e4526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
    "wine_df[\"label\"] = wine.target\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb8f12a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "            label  \n",
       "count  178.000000  \n",
       "mean     0.938202  \n",
       "std      0.775035  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02efdc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95b723d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine_df.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4906289",
   "metadata": {},
   "source": [
    "## 4. train, test 데이터 분리\n",
    "모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
    "X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7e18cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  142 , X_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn model_selection패키지의 train_test_split 함수를 임포트\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))\n",
    "# len은 배열의 길이를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef820e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((142, 13), (142,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "# train의 형상정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73c8353e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36, 13), (36,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape\n",
    "# test의 형상정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10210052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        2, 0, 2, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 0, 0, 0,\n",
       "        0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 1,\n",
       "        0, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 2,\n",
       "        1, 2, 0, 0, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 1, 2, 0, 1,\n",
       "        1, 1, 0, 2, 1, 1, 2, 1, 0, 2]),\n",
       " array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "        1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test\n",
    "# label이 잘 분리되었는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573d5e2",
   "metadata": {},
   "source": [
    "## 5. 다양한 모델로 학습시켜보기\n",
    "학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
    "\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc4e68",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f343a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train) \n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba0dd5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07bd0f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802d611",
   "metadata": {},
   "source": [
    "### SVM 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1b08932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf1f3e",
   "metadata": {},
   "source": [
    "### SGD Classifier 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b845daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64         7\n",
      "           1       0.71      0.88      0.79        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.39      0.63      0.48        36\n",
      "weighted avg       0.43      0.61      0.50        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "y_pred = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee5afb",
   "metadata": {},
   "source": [
    "### Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6b9a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # 선형분류기인 LogisticRegression를 사용하기 위한 import\n",
    "logistic_model = LogisticRegression() # 모델 객체 생성\n",
    "\n",
    "logistic_model.fit(X_train, y_train) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred = logistic_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c958896",
   "metadata": {},
   "source": [
    "## 6. 모델을 평가해 보기\n",
    "학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43cfbb",
   "metadata": {},
   "source": [
    "### Macro F1 score을 사용하였습니다.\n",
    "\n",
    "F1 Score는 Precision과 Recall의 조화 평균으로 계산되며, 모델이 클래스 불균형 문제를 얼마나 잘 처리하는지 측정하는 데 도움이 된다.\n",
    "\n",
    "Macro F1 Score는 다중 클래스 분류 문제에서 모델의 성능을 평가하는 데 사용되는 지표 중 하나이다. \n",
    "Macro F1 Score는 각 클래스별로 계산된 F1 Score의 평균을 구하여 모델의 전체 성능을 평가한다. \n",
    "\n",
    "Macro F1 Score는 모든 클래스에 대한 F1 Score의 평균으로 계산됩니다.\n",
    "\n",
    "- F1 Score = $2 * \\frac{Precision * Recall}{Precision + Recall}$\n",
    "\n",
    "wine data는 class 0이 59개, 1이 71개, 2가 48개로 레이블이 약간 불균형하기에 f1 score을 이용하고자 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3dc257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def macro_f1_score(y_true, y_pred, n_classes):\n",
    "    f1_scores = []\n",
    "    for c in range(n_classes):\n",
    "        y_true_c = (y_true == c)\n",
    "        y_pred_c = (y_pred == c)\n",
    "        f1_c = f1_score(y_true_c, y_pred_c)\n",
    "        f1_scores.append(f1_c)\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "# Macro F1 Score 계산\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a38ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Macro F1 Score >\n",
      "decision_tree : 0.9511784511784511\n",
      "random_forest : 1.0\n",
      "svm_model : 0.5627168696936139\n",
      "sgd_model  : 0.41478129713423834\n",
      "logistic_model : 0.9648351648351648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print('< Macro F1 Score >')\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train) \n",
    "y_pred = decision_tree.predict(X_test)\n",
    "macro_f1 = macro_f1_score(y_test, y_pred, n_classes)\n",
    "print(\"decision_tree :\", macro_f1)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test)\n",
    "macro_f1 = macro_f1_score(y_test, y_pred, n_classes)\n",
    "print(\"random_forest :\", macro_f1)\n",
    "\n",
    "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
    "svm_model.fit(X_train, y_train) # 훈련\n",
    "y_pred = svm_model.predict(X_test)\n",
    "macro_f1 = macro_f1_score(y_test, y_pred, n_classes)\n",
    "print(\"svm_model :\", macro_f1)\n",
    "\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "macro_f1 = macro_f1_score(y_test, y_pred, n_classes)\n",
    "print(\"sgd_model  :\", macro_f1)\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train) \n",
    "y_pred = logistic_model.predict(X_test)\n",
    "macro_f1 = macro_f1_score(y_test, y_pred, n_classes)\n",
    "print(\"logistic_model :\", macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25570c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
